{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "\n",
    "import codecs\n",
    "import collections\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, data_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size, infer=False):#\n",
    "\n",
    "        \n",
    "        if infer:\n",
    "            batch_size = 1\n",
    "            seq_length = 1\n",
    "\n",
    "        \n",
    "        cell_fn = rnn.BasicLSTMCell\n",
    "\n",
    "        cells = []\n",
    "        for _ in range(num_layers):\n",
    "            cell = cell_fn(rnn_size)\n",
    "            cells.append(cell)\n",
    "        self.cell = cell = rnn.MultiRNNCell(cells)\n",
    "        self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.targets = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        self.batch_pointer = tf.Variable(0, name=\"batch_pointer\", trainable=True, dtype=tf.int32)\n",
    "        self.inc_batch_pointer_op = tf.assign(self.batch_pointer, self.batch_pointer + 1)\n",
    "        self.epoch_pointer = tf.Variable(0, name=\"epoch_pointer\", trainable=False)\n",
    "        self.batch_time = tf.Variable(0.0, name=\"batch_time\", trainable=False)\n",
    "        tf.summary.scalar(\"time_batch\", self.batch_time)\n",
    "        def variable_summaries(var):\n",
    "            with tf.name_scope('summaries'):\n",
    "                mean = tf.reduce_mean(var)\n",
    "                tf.summary.scalar('mean', mean)\n",
    "                tf.summary.scalar('max', tf.reduce_max(var))\n",
    "                tf.summary.scalar('min', tf.reduce_min(var))\n",
    "\n",
    "        with tf.variable_scope('rnnlm'):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "            variable_summaries(softmax_w)\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "            variable_summaries(softmax_b)\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "                inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), seq_length, 1)\n",
    "                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, loop_function=loop, scope='rnnlm')\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                [tf.reshape(self.targets, [-1])],\n",
    "                [tf.ones([batch_size * seq_length])],\n",
    "                vocab_size)\n",
    "        self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        tf.summary.scalar(\"cost\", self.cost)\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),\n",
    "                grad_clip)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    def sample(self, sess, words, vocab, num, prime='first', sampling_type=1):\n",
    "        '''\n",
    "        This function is used to generate text, based on a saved model, with\n",
    "        a text as input.\n",
    "        It returns a string, composed of words chosen one by one by the model.\n",
    "        '''\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "\n",
    "        \n",
    "        ret = ''\n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "        ret = prime\n",
    "        word = prime.split()[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab.get(word, 0)\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = probs[0]\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if word == '\\n':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else:\n",
    "                sample = weighted_pick(p)\n",
    "            pred = words[sample]\n",
    "            ret += ' ' + pred\n",
    "            word = pred\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor is:[ 1656  4283  6392 ...  7382 11376 10369]\n",
      "It's shape: (111811,)\n",
      "number of batches is: 11181\n",
      "The shape of the new tensor is: (111810,)\n",
      "[ 1656  4283  6392 ...  5111  7382 11376]  and  [ 4283  6392  2016 ...  7382 11376 11376]\n",
      "WARNING:tensorflow:From <ipython-input-1-eaa56d45b15d>:30: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "0/559050 (epoch 0), train_loss = 9.385, time/batch = 0.111\n",
      "model saved to C:\\Users\\SAIKUMAR\\Desktop\\vikram vqa\\__MACOSX\\caption_sneak\\data/model_test.ckpt\n",
      "2/559050 (epoch 0), train_loss = 9.386, time/batch = 0.092\n",
      "4/559050 (epoch 0), train_loss = 9.380, time/batch = 0.095\n",
      "6/559050 (epoch 0), train_loss = 9.370, time/batch = 0.083\n",
      "8/559050 (epoch 0), train_loss = 9.293, time/batch = 0.084\n",
      "10/559050 (epoch 0), train_loss = 9.192, time/batch = 0.089\n",
      "12/559050 (epoch 0), train_loss = 8.426, time/batch = 0.080\n",
      "14/559050 (epoch 0), train_loss = 8.078, time/batch = 0.087\n",
      "16/559050 (epoch 0), train_loss = 8.307, time/batch = 0.085\n",
      "18/559050 (epoch 0), train_loss = 7.747, time/batch = 0.089\n",
      "20/559050 (epoch 0), train_loss = 7.995, time/batch = 0.084\n",
      "22/559050 (epoch 0), train_loss = 8.165, time/batch = 0.100\n",
      "24/559050 (epoch 0), train_loss = 8.333, time/batch = 0.080\n",
      "26/559050 (epoch 0), train_loss = 10.040, time/batch = 0.082\n",
      "28/559050 (epoch 0), train_loss = 9.049, time/batch = 0.080\n",
      "30/559050 (epoch 0), train_loss = 9.052, time/batch = 0.081\n",
      "32/559050 (epoch 0), train_loss = 8.073, time/batch = 0.081\n",
      "34/559050 (epoch 0), train_loss = 7.973, time/batch = 0.083\n",
      "36/559050 (epoch 0), train_loss = 7.580, time/batch = 0.084\n",
      "38/559050 (epoch 0), train_loss = 8.553, time/batch = 0.082\n",
      "40/559050 (epoch 0), train_loss = 7.774, time/batch = 0.083\n",
      "42/559050 (epoch 0), train_loss = 7.916, time/batch = 0.078\n",
      "44/559050 (epoch 0), train_loss = 7.798, time/batch = 0.081\n",
      "46/559050 (epoch 0), train_loss = 7.188, time/batch = 0.081\n",
      "48/559050 (epoch 0), train_loss = 9.342, time/batch = 0.076\n",
      "50/559050 (epoch 0), train_loss = 7.585, time/batch = 0.080\n",
      "52/559050 (epoch 0), train_loss = 6.133, time/batch = 0.078\n",
      "54/559050 (epoch 0), train_loss = 6.691, time/batch = 0.078\n",
      "56/559050 (epoch 0), train_loss = 7.320, time/batch = 0.077\n",
      "58/559050 (epoch 0), train_loss = 6.664, time/batch = 0.080\n",
      "60/559050 (epoch 0), train_loss = 8.430, time/batch = 0.076\n",
      "62/559050 (epoch 0), train_loss = 8.271, time/batch = 0.082\n",
      "64/559050 (epoch 0), train_loss = 7.482, time/batch = 0.077\n",
      "66/559050 (epoch 0), train_loss = 7.716, time/batch = 0.080\n",
      "68/559050 (epoch 0), train_loss = 6.732, time/batch = 0.077\n",
      "70/559050 (epoch 0), train_loss = 7.077, time/batch = 0.080\n",
      "72/559050 (epoch 0), train_loss = 6.044, time/batch = 0.078\n",
      "74/559050 (epoch 0), train_loss = 7.206, time/batch = 0.080\n",
      "76/559050 (epoch 0), train_loss = 7.016, time/batch = 0.078\n",
      "78/559050 (epoch 0), train_loss = 7.015, time/batch = 0.077\n",
      "80/559050 (epoch 0), train_loss = 8.161, time/batch = 0.079\n",
      "82/559050 (epoch 0), train_loss = 6.664, time/batch = 0.080\n",
      "84/559050 (epoch 0), train_loss = 7.320, time/batch = 0.080\n",
      "86/559050 (epoch 0), train_loss = 7.378, time/batch = 0.082\n",
      "88/559050 (epoch 0), train_loss = 7.809, time/batch = 0.079\n",
      "90/559050 (epoch 0), train_loss = 6.410, time/batch = 0.077\n",
      "92/559050 (epoch 0), train_loss = 6.831, time/batch = 0.079\n",
      "94/559050 (epoch 0), train_loss = 6.943, time/batch = 0.079\n",
      "96/559050 (epoch 0), train_loss = 8.477, time/batch = 0.081\n",
      "98/559050 (epoch 0), train_loss = 7.878, time/batch = 0.081\n",
      "100/559050 (epoch 0), train_loss = 8.169, time/batch = 0.081\n",
      "102/559050 (epoch 0), train_loss = 6.451, time/batch = 0.083\n",
      "104/559050 (epoch 0), train_loss = 6.611, time/batch = 0.088\n",
      "106/559050 (epoch 0), train_loss = 6.047, time/batch = 0.094\n",
      "108/559050 (epoch 0), train_loss = 6.556, time/batch = 0.078\n",
      "110/559050 (epoch 0), train_loss = 6.469, time/batch = 0.083\n",
      "112/559050 (epoch 0), train_loss = 6.969, time/batch = 0.075\n",
      "114/559050 (epoch 0), train_loss = 6.934, time/batch = 0.089\n",
      "116/559050 (epoch 0), train_loss = 7.351, time/batch = 0.086\n",
      "118/559050 (epoch 0), train_loss = 7.518, time/batch = 0.085\n",
      "120/559050 (epoch 0), train_loss = 8.244, time/batch = 0.091\n",
      "122/559050 (epoch 0), train_loss = 7.273, time/batch = 0.094\n",
      "124/559050 (epoch 0), train_loss = 6.479, time/batch = 0.093\n",
      "126/559050 (epoch 0), train_loss = 5.680, time/batch = 0.090\n",
      "128/559050 (epoch 0), train_loss = 7.124, time/batch = 0.082\n",
      "130/559050 (epoch 0), train_loss = 6.285, time/batch = 0.080\n",
      "132/559050 (epoch 0), train_loss = 7.565, time/batch = 0.088\n",
      "134/559050 (epoch 0), train_loss = 6.991, time/batch = 0.083\n",
      "136/559050 (epoch 0), train_loss = 8.406, time/batch = 0.080\n",
      "138/559050 (epoch 0), train_loss = 7.470, time/batch = 0.081\n",
      "140/559050 (epoch 0), train_loss = 7.894, time/batch = 0.078\n",
      "142/559050 (epoch 0), train_loss = 6.802, time/batch = 0.083\n",
      "144/559050 (epoch 0), train_loss = 7.134, time/batch = 0.082\n",
      "146/559050 (epoch 0), train_loss = 6.103, time/batch = 0.095\n",
      "148/559050 (epoch 0), train_loss = 7.235, time/batch = 0.091\n",
      "150/559050 (epoch 0), train_loss = 6.954, time/batch = 0.084\n",
      "152/559050 (epoch 0), train_loss = 7.332, time/batch = 0.094\n",
      "154/559050 (epoch 0), train_loss = 6.561, time/batch = 0.093\n",
      "156/559050 (epoch 0), train_loss = 6.492, time/batch = 0.094\n",
      "158/559050 (epoch 0), train_loss = 7.437, time/batch = 0.087\n",
      "160/559050 (epoch 0), train_loss = 6.224, time/batch = 0.081\n",
      "162/559050 (epoch 0), train_loss = 4.690, time/batch = 0.076\n",
      "164/559050 (epoch 0), train_loss = 6.484, time/batch = 0.085\n",
      "166/559050 (epoch 0), train_loss = 6.946, time/batch = 0.094\n",
      "168/559050 (epoch 0), train_loss = 5.064, time/batch = 0.091\n",
      "170/559050 (epoch 0), train_loss = 6.612, time/batch = 0.090\n",
      "172/559050 (epoch 0), train_loss = 6.431, time/batch = 0.094\n",
      "174/559050 (epoch 0), train_loss = 6.597, time/batch = 0.086\n",
      "176/559050 (epoch 0), train_loss = 4.910, time/batch = 0.093\n",
      "178/559050 (epoch 0), train_loss = 6.628, time/batch = 0.093\n",
      "180/559050 (epoch 0), train_loss = 6.823, time/batch = 0.093\n",
      "182/559050 (epoch 0), train_loss = 5.920, time/batch = 0.089\n",
      "184/559050 (epoch 0), train_loss = 7.449, time/batch = 0.094\n",
      "186/559050 (epoch 0), train_loss = 6.569, time/batch = 0.081\n",
      "188/559050 (epoch 0), train_loss = 6.517, time/batch = 0.080\n",
      "190/559050 (epoch 0), train_loss = 6.546, time/batch = 0.082\n",
      "192/559050 (epoch 0), train_loss = 5.631, time/batch = 0.083\n",
      "194/559050 (epoch 0), train_loss = 6.477, time/batch = 0.079\n",
      "196/559050 (epoch 0), train_loss = 6.886, time/batch = 0.081\n",
      "198/559050 (epoch 0), train_loss = 6.314, time/batch = 0.084\n",
      "200/559050 (epoch 0), train_loss = 7.712, time/batch = 0.081\n",
      "202/559050 (epoch 0), train_loss = 6.596, time/batch = 0.087\n",
      "204/559050 (epoch 0), train_loss = 5.744, time/batch = 0.092\n",
      "206/559050 (epoch 0), train_loss = 6.912, time/batch = 0.091\n",
      "208/559050 (epoch 0), train_loss = 7.561, time/batch = 0.091\n",
      "210/559050 (epoch 0), train_loss = 6.002, time/batch = 0.100\n",
      "212/559050 (epoch 0), train_loss = 7.048, time/batch = 0.095\n",
      "214/559050 (epoch 0), train_loss = 5.848, time/batch = 0.085\n",
      "216/559050 (epoch 0), train_loss = 7.521, time/batch = 0.081\n",
      "218/559050 (epoch 0), train_loss = 7.989, time/batch = 0.085\n",
      "220/559050 (epoch 0), train_loss = 6.924, time/batch = 0.084\n",
      "222/559050 (epoch 0), train_loss = 5.681, time/batch = 0.083\n",
      "224/559050 (epoch 0), train_loss = 6.928, time/batch = 0.085\n",
      "226/559050 (epoch 0), train_loss = 7.051, time/batch = 0.084\n",
      "228/559050 (epoch 0), train_loss = 6.309, time/batch = 0.084\n",
      "230/559050 (epoch 0), train_loss = 6.755, time/batch = 0.082\n",
      "232/559050 (epoch 0), train_loss = 5.106, time/batch = 0.082\n",
      "234/559050 (epoch 0), train_loss = 7.198, time/batch = 0.083\n",
      "236/559050 (epoch 0), train_loss = 6.861, time/batch = 0.085\n",
      "238/559050 (epoch 0), train_loss = 6.375, time/batch = 0.081\n",
      "240/559050 (epoch 0), train_loss = 7.109, time/batch = 0.079\n",
      "242/559050 (epoch 0), train_loss = 5.743, time/batch = 0.085\n",
      "244/559050 (epoch 0), train_loss = 6.998, time/batch = 0.082\n",
      "246/559050 (epoch 0), train_loss = 7.713, time/batch = 0.083\n",
      "248/559050 (epoch 0), train_loss = 8.142, time/batch = 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/559050 (epoch 0), train_loss = 6.594, time/batch = 0.086\n",
      "252/559050 (epoch 0), train_loss = 5.838, time/batch = 0.085\n",
      "254/559050 (epoch 0), train_loss = 6.914, time/batch = 0.085\n",
      "256/559050 (epoch 0), train_loss = 5.952, time/batch = 0.092\n",
      "258/559050 (epoch 0), train_loss = 7.545, time/batch = 0.095\n",
      "260/559050 (epoch 0), train_loss = 5.606, time/batch = 0.089\n",
      "262/559050 (epoch 0), train_loss = 7.003, time/batch = 0.089\n",
      "264/559050 (epoch 0), train_loss = 7.193, time/batch = 0.084\n",
      "266/559050 (epoch 0), train_loss = 6.747, time/batch = 0.087\n",
      "268/559050 (epoch 0), train_loss = 7.482, time/batch = 0.090\n",
      "270/559050 (epoch 0), train_loss = 7.293, time/batch = 0.087\n",
      "272/559050 (epoch 0), train_loss = 6.615, time/batch = 0.090\n",
      "274/559050 (epoch 0), train_loss = 5.137, time/batch = 0.089\n",
      "276/559050 (epoch 0), train_loss = 6.637, time/batch = 0.089\n",
      "278/559050 (epoch 0), train_loss = 7.439, time/batch = 0.087\n",
      "280/559050 (epoch 0), train_loss = 6.583, time/batch = 0.084\n",
      "282/559050 (epoch 0), train_loss = 7.446, time/batch = 0.080\n",
      "284/559050 (epoch 0), train_loss = 6.920, time/batch = 0.084\n",
      "286/559050 (epoch 0), train_loss = 6.928, time/batch = 0.087\n",
      "288/559050 (epoch 0), train_loss = 8.244, time/batch = 0.098\n",
      "290/559050 (epoch 0), train_loss = 5.723, time/batch = 0.095\n",
      "292/559050 (epoch 0), train_loss = 7.155, time/batch = 0.084\n",
      "294/559050 (epoch 0), train_loss = 6.913, time/batch = 0.083\n",
      "296/559050 (epoch 0), train_loss = 5.994, time/batch = 0.081\n",
      "298/559050 (epoch 0), train_loss = 6.141, time/batch = 0.086\n",
      "300/559050 (epoch 0), train_loss = 7.181, time/batch = 0.081\n",
      "302/559050 (epoch 0), train_loss = 6.208, time/batch = 0.080\n",
      "304/559050 (epoch 0), train_loss = 8.089, time/batch = 0.083\n",
      "306/559050 (epoch 0), train_loss = 5.989, time/batch = 0.087\n",
      "308/559050 (epoch 0), train_loss = 7.820, time/batch = 0.091\n",
      "310/559050 (epoch 0), train_loss = 6.954, time/batch = 0.100\n",
      "312/559050 (epoch 0), train_loss = 6.227, time/batch = 0.092\n",
      "314/559050 (epoch 0), train_loss = 8.076, time/batch = 0.092\n",
      "316/559050 (epoch 0), train_loss = 6.403, time/batch = 0.087\n",
      "318/559050 (epoch 0), train_loss = 7.904, time/batch = 0.089\n",
      "320/559050 (epoch 0), train_loss = 6.747, time/batch = 0.092\n",
      "322/559050 (epoch 0), train_loss = 8.769, time/batch = 0.089\n",
      "324/559050 (epoch 0), train_loss = 7.854, time/batch = 0.089\n",
      "326/559050 (epoch 0), train_loss = 6.977, time/batch = 0.089\n",
      "328/559050 (epoch 0), train_loss = 7.485, time/batch = 0.088\n",
      "330/559050 (epoch 0), train_loss = 8.080, time/batch = 0.090\n",
      "332/559050 (epoch 0), train_loss = 7.278, time/batch = 0.087\n",
      "334/559050 (epoch 0), train_loss = 8.467, time/batch = 0.087\n",
      "336/559050 (epoch 0), train_loss = 6.652, time/batch = 0.089\n",
      "338/559050 (epoch 0), train_loss = 6.770, time/batch = 0.085\n",
      "340/559050 (epoch 0), train_loss = 6.355, time/batch = 0.084\n",
      "342/559050 (epoch 0), train_loss = 6.713, time/batch = 0.086\n",
      "344/559050 (epoch 0), train_loss = 7.420, time/batch = 0.082\n",
      "346/559050 (epoch 0), train_loss = 6.126, time/batch = 0.083\n",
      "348/559050 (epoch 0), train_loss = 5.239, time/batch = 0.089\n",
      "350/559050 (epoch 0), train_loss = 7.244, time/batch = 0.097\n",
      "352/559050 (epoch 0), train_loss = 6.529, time/batch = 0.089\n",
      "354/559050 (epoch 0), train_loss = 7.516, time/batch = 0.084\n",
      "356/559050 (epoch 0), train_loss = 7.640, time/batch = 0.083\n",
      "358/559050 (epoch 0), train_loss = 7.422, time/batch = 0.099\n",
      "360/559050 (epoch 0), train_loss = 6.934, time/batch = 0.095\n",
      "362/559050 (epoch 0), train_loss = 5.756, time/batch = 0.098\n",
      "364/559050 (epoch 0), train_loss = 6.811, time/batch = 0.096\n",
      "366/559050 (epoch 0), train_loss = 7.868, time/batch = 0.098\n",
      "368/559050 (epoch 0), train_loss = 6.912, time/batch = 0.093\n",
      "370/559050 (epoch 0), train_loss = 6.924, time/batch = 0.082\n",
      "372/559050 (epoch 0), train_loss = 6.921, time/batch = 0.096\n",
      "374/559050 (epoch 0), train_loss = 7.435, time/batch = 0.100\n",
      "376/559050 (epoch 0), train_loss = 5.494, time/batch = 0.086\n",
      "378/559050 (epoch 0), train_loss = 5.869, time/batch = 0.096\n",
      "380/559050 (epoch 0), train_loss = 6.521, time/batch = 0.087\n",
      "382/559050 (epoch 0), train_loss = 5.911, time/batch = 0.086\n",
      "384/559050 (epoch 0), train_loss = 5.573, time/batch = 0.084\n",
      "386/559050 (epoch 0), train_loss = 8.222, time/batch = 0.088\n",
      "388/559050 (epoch 0), train_loss = 6.475, time/batch = 0.084\n",
      "390/559050 (epoch 0), train_loss = 6.432, time/batch = 0.086\n",
      "392/559050 (epoch 0), train_loss = 5.635, time/batch = 0.098\n",
      "394/559050 (epoch 0), train_loss = 6.211, time/batch = 0.094\n",
      "396/559050 (epoch 0), train_loss = 6.932, time/batch = 0.091\n",
      "398/559050 (epoch 0), train_loss = 6.116, time/batch = 0.088\n",
      "400/559050 (epoch 0), train_loss = 7.437, time/batch = 0.095\n",
      "402/559050 (epoch 0), train_loss = 6.942, time/batch = 0.085\n",
      "404/559050 (epoch 0), train_loss = 6.069, time/batch = 0.089\n",
      "406/559050 (epoch 0), train_loss = 6.302, time/batch = 0.090\n",
      "408/559050 (epoch 0), train_loss = 6.221, time/batch = 0.093\n",
      "410/559050 (epoch 0), train_loss = 7.040, time/batch = 0.092\n",
      "412/559050 (epoch 0), train_loss = 6.970, time/batch = 0.085\n",
      "414/559050 (epoch 0), train_loss = 5.940, time/batch = 0.082\n",
      "416/559050 (epoch 0), train_loss = 6.564, time/batch = 0.082\n",
      "418/559050 (epoch 0), train_loss = 6.610, time/batch = 0.085\n",
      "420/559050 (epoch 0), train_loss = 6.888, time/batch = 0.080\n",
      "422/559050 (epoch 0), train_loss = 6.618, time/batch = 0.083\n",
      "424/559050 (epoch 0), train_loss = 7.321, time/batch = 0.085\n",
      "426/559050 (epoch 0), train_loss = 7.687, time/batch = 0.083\n",
      "428/559050 (epoch 0), train_loss = 7.456, time/batch = 0.083\n",
      "430/559050 (epoch 0), train_loss = 4.958, time/batch = 0.085\n",
      "432/559050 (epoch 0), train_loss = 6.909, time/batch = 0.079\n",
      "434/559050 (epoch 0), train_loss = 5.815, time/batch = 0.082\n",
      "436/559050 (epoch 0), train_loss = 7.123, time/batch = 0.083\n",
      "438/559050 (epoch 0), train_loss = 7.007, time/batch = 0.082\n",
      "440/559050 (epoch 0), train_loss = 5.557, time/batch = 0.079\n",
      "442/559050 (epoch 0), train_loss = 5.630, time/batch = 0.085\n",
      "444/559050 (epoch 0), train_loss = 6.864, time/batch = 0.081\n",
      "446/559050 (epoch 0), train_loss = 8.406, time/batch = 0.086\n",
      "448/559050 (epoch 0), train_loss = 7.290, time/batch = 0.079\n",
      "450/559050 (epoch 0), train_loss = 5.076, time/batch = 0.083\n",
      "452/559050 (epoch 0), train_loss = 6.681, time/batch = 0.081\n",
      "454/559050 (epoch 0), train_loss = 5.641, time/batch = 0.084\n",
      "456/559050 (epoch 0), train_loss = 7.448, time/batch = 0.082\n",
      "458/559050 (epoch 0), train_loss = 6.015, time/batch = 0.084\n",
      "460/559050 (epoch 0), train_loss = 7.651, time/batch = 0.086\n",
      "462/559050 (epoch 0), train_loss = 5.971, time/batch = 0.081\n",
      "464/559050 (epoch 0), train_loss = 6.484, time/batch = 0.084\n",
      "466/559050 (epoch 0), train_loss = 5.946, time/batch = 0.084\n",
      "468/559050 (epoch 0), train_loss = 5.979, time/batch = 0.087\n",
      "470/559050 (epoch 0), train_loss = 5.551, time/batch = 0.084\n",
      "472/559050 (epoch 0), train_loss = 5.815, time/batch = 0.083\n",
      "474/559050 (epoch 0), train_loss = 7.065, time/batch = 0.108\n",
      "476/559050 (epoch 0), train_loss = 5.264, time/batch = 0.088\n",
      "478/559050 (epoch 0), train_loss = 6.543, time/batch = 0.081\n",
      "480/559050 (epoch 0), train_loss = 7.317, time/batch = 0.084\n",
      "482/559050 (epoch 0), train_loss = 6.743, time/batch = 0.083\n",
      "484/559050 (epoch 0), train_loss = 6.120, time/batch = 0.086\n",
      "486/559050 (epoch 0), train_loss = 6.090, time/batch = 0.085\n",
      "488/559050 (epoch 0), train_loss = 7.312, time/batch = 0.082\n",
      "490/559050 (epoch 0), train_loss = 5.937, time/batch = 0.085\n",
      "492/559050 (epoch 0), train_loss = 7.097, time/batch = 0.086\n",
      "494/559050 (epoch 0), train_loss = 6.458, time/batch = 0.085\n",
      "496/559050 (epoch 0), train_loss = 5.812, time/batch = 0.087\n",
      "498/559050 (epoch 0), train_loss = 6.534, time/batch = 0.085\n",
      "500/559050 (epoch 0), train_loss = 6.531, time/batch = 0.087\n",
      "502/559050 (epoch 0), train_loss = 6.904, time/batch = 0.086\n",
      "504/559050 (epoch 0), train_loss = 6.152, time/batch = 0.086\n",
      "506/559050 (epoch 0), train_loss = 6.277, time/batch = 0.085\n",
      "508/559050 (epoch 0), train_loss = 5.804, time/batch = 0.085\n",
      "510/559050 (epoch 0), train_loss = 7.866, time/batch = 0.087\n",
      "512/559050 (epoch 0), train_loss = 5.637, time/batch = 0.083\n",
      "514/559050 (epoch 0), train_loss = 6.972, time/batch = 0.088\n",
      "516/559050 (epoch 0), train_loss = 7.201, time/batch = 0.084\n",
      "518/559050 (epoch 0), train_loss = 7.349, time/batch = 0.087\n",
      "520/559050 (epoch 0), train_loss = 8.188, time/batch = 0.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/559050 (epoch 0), train_loss = 6.195, time/batch = 0.085\n",
      "524/559050 (epoch 0), train_loss = 6.861, time/batch = 0.085\n",
      "526/559050 (epoch 0), train_loss = 7.467, time/batch = 0.084\n",
      "528/559050 (epoch 0), train_loss = 7.558, time/batch = 0.087\n",
      "530/559050 (epoch 0), train_loss = 6.592, time/batch = 0.086\n",
      "532/559050 (epoch 0), train_loss = 6.372, time/batch = 0.083\n",
      "534/559050 (epoch 0), train_loss = 7.322, time/batch = 0.086\n",
      "536/559050 (epoch 0), train_loss = 7.028, time/batch = 0.085\n",
      "538/559050 (epoch 0), train_loss = 7.962, time/batch = 0.083\n",
      "540/559050 (epoch 0), train_loss = 7.936, time/batch = 0.085\n",
      "542/559050 (epoch 0), train_loss = 6.607, time/batch = 0.087\n",
      "544/559050 (epoch 0), train_loss = 8.291, time/batch = 0.088\n",
      "546/559050 (epoch 0), train_loss = 8.516, time/batch = 0.088\n",
      "548/559050 (epoch 0), train_loss = 7.276, time/batch = 0.085\n",
      "550/559050 (epoch 0), train_loss = 6.977, time/batch = 0.086\n",
      "552/559050 (epoch 0), train_loss = 7.917, time/batch = 0.084\n",
      "554/559050 (epoch 0), train_loss = 6.948, time/batch = 0.085\n",
      "556/559050 (epoch 0), train_loss = 7.500, time/batch = 0.085\n",
      "558/559050 (epoch 0), train_loss = 7.337, time/batch = 0.086\n",
      "560/559050 (epoch 0), train_loss = 6.488, time/batch = 0.087\n",
      "562/559050 (epoch 0), train_loss = 5.819, time/batch = 0.084\n",
      "564/559050 (epoch 0), train_loss = 6.632, time/batch = 0.089\n",
      "566/559050 (epoch 0), train_loss = 7.071, time/batch = 0.086\n",
      "568/559050 (epoch 0), train_loss = 7.145, time/batch = 0.084\n",
      "570/559050 (epoch 0), train_loss = 5.905, time/batch = 0.085\n",
      "572/559050 (epoch 0), train_loss = 6.187, time/batch = 0.086\n",
      "574/559050 (epoch 0), train_loss = 5.839, time/batch = 0.087\n",
      "576/559050 (epoch 0), train_loss = 7.860, time/batch = 0.084\n",
      "578/559050 (epoch 0), train_loss = 8.779, time/batch = 0.085\n",
      "580/559050 (epoch 0), train_loss = 8.164, time/batch = 0.085\n",
      "582/559050 (epoch 0), train_loss = 9.421, time/batch = 0.085\n",
      "584/559050 (epoch 0), train_loss = 6.836, time/batch = 0.084\n",
      "586/559050 (epoch 0), train_loss = 6.138, time/batch = 0.085\n",
      "588/559050 (epoch 0), train_loss = 5.896, time/batch = 0.085\n",
      "590/559050 (epoch 0), train_loss = 5.968, time/batch = 0.084\n",
      "592/559050 (epoch 0), train_loss = 6.755, time/batch = 0.085\n",
      "594/559050 (epoch 0), train_loss = 6.688, time/batch = 0.082\n",
      "596/559050 (epoch 0), train_loss = 6.371, time/batch = 0.083\n",
      "598/559050 (epoch 0), train_loss = 6.428, time/batch = 0.085\n",
      "600/559050 (epoch 0), train_loss = 6.034, time/batch = 0.083\n",
      "602/559050 (epoch 0), train_loss = 7.088, time/batch = 0.084\n",
      "604/559050 (epoch 0), train_loss = 7.464, time/batch = 0.084\n",
      "606/559050 (epoch 0), train_loss = 6.519, time/batch = 0.084\n",
      "608/559050 (epoch 0), train_loss = 6.173, time/batch = 0.084\n",
      "610/559050 (epoch 0), train_loss = 6.690, time/batch = 0.085\n",
      "612/559050 (epoch 0), train_loss = 7.236, time/batch = 0.082\n",
      "614/559050 (epoch 0), train_loss = 7.372, time/batch = 0.092\n",
      "616/559050 (epoch 0), train_loss = 8.670, time/batch = 0.093\n",
      "618/559050 (epoch 0), train_loss = 7.263, time/batch = 0.089\n",
      "620/559050 (epoch 0), train_loss = 7.300, time/batch = 0.089\n",
      "622/559050 (epoch 0), train_loss = 6.586, time/batch = 0.089\n",
      "624/559050 (epoch 0), train_loss = 5.357, time/batch = 0.090\n",
      "626/559050 (epoch 0), train_loss = 7.165, time/batch = 0.088\n",
      "628/559050 (epoch 0), train_loss = 8.033, time/batch = 0.089\n",
      "630/559050 (epoch 0), train_loss = 7.980, time/batch = 0.088\n",
      "632/559050 (epoch 0), train_loss = 6.807, time/batch = 0.088\n",
      "634/559050 (epoch 0), train_loss = 6.408, time/batch = 0.088\n",
      "636/559050 (epoch 0), train_loss = 6.407, time/batch = 0.091\n",
      "638/559050 (epoch 0), train_loss = 6.416, time/batch = 0.087\n",
      "640/559050 (epoch 0), train_loss = 5.452, time/batch = 0.090\n",
      "642/559050 (epoch 0), train_loss = 7.119, time/batch = 0.084\n",
      "644/559050 (epoch 0), train_loss = 6.807, time/batch = 0.089\n",
      "646/559050 (epoch 0), train_loss = 6.984, time/batch = 0.089\n",
      "648/559050 (epoch 0), train_loss = 7.576, time/batch = 0.082\n",
      "650/559050 (epoch 0), train_loss = 6.634, time/batch = 0.083\n",
      "652/559050 (epoch 0), train_loss = 6.542, time/batch = 0.083\n",
      "654/559050 (epoch 0), train_loss = 5.836, time/batch = 0.084\n",
      "656/559050 (epoch 0), train_loss = 6.782, time/batch = 0.083\n",
      "658/559050 (epoch 0), train_loss = 7.210, time/batch = 0.085\n",
      "660/559050 (epoch 0), train_loss = 6.292, time/batch = 0.081\n",
      "662/559050 (epoch 0), train_loss = 7.908, time/batch = 0.083\n",
      "664/559050 (epoch 0), train_loss = 8.307, time/batch = 0.082\n",
      "666/559050 (epoch 0), train_loss = 7.162, time/batch = 0.083\n",
      "668/559050 (epoch 0), train_loss = 6.618, time/batch = 0.083\n",
      "670/559050 (epoch 0), train_loss = 5.957, time/batch = 0.083\n",
      "672/559050 (epoch 0), train_loss = 7.307, time/batch = 0.082\n",
      "674/559050 (epoch 0), train_loss = 7.443, time/batch = 0.085\n",
      "676/559050 (epoch 0), train_loss = 5.506, time/batch = 0.083\n",
      "678/559050 (epoch 0), train_loss = 6.307, time/batch = 0.082\n",
      "680/559050 (epoch 0), train_loss = 6.635, time/batch = 0.083\n",
      "682/559050 (epoch 0), train_loss = 5.600, time/batch = 0.084\n",
      "684/559050 (epoch 0), train_loss = 6.941, time/batch = 0.079\n",
      "686/559050 (epoch 0), train_loss = 6.321, time/batch = 0.082\n",
      "688/559050 (epoch 0), train_loss = 6.406, time/batch = 0.084\n",
      "690/559050 (epoch 0), train_loss = 7.277, time/batch = 0.084\n",
      "692/559050 (epoch 0), train_loss = 8.085, time/batch = 0.081\n",
      "694/559050 (epoch 0), train_loss = 7.999, time/batch = 0.081\n",
      "696/559050 (epoch 0), train_loss = 6.778, time/batch = 0.081\n",
      "698/559050 (epoch 0), train_loss = 6.877, time/batch = 0.082\n",
      "700/559050 (epoch 0), train_loss = 7.133, time/batch = 0.082\n",
      "702/559050 (epoch 0), train_loss = 6.750, time/batch = 0.084\n",
      "704/559050 (epoch 0), train_loss = 7.879, time/batch = 0.080\n",
      "706/559050 (epoch 0), train_loss = 6.184, time/batch = 0.082\n",
      "708/559050 (epoch 0), train_loss = 8.622, time/batch = 0.084\n",
      "710/559050 (epoch 0), train_loss = 6.589, time/batch = 0.082\n",
      "712/559050 (epoch 0), train_loss = 6.649, time/batch = 0.084\n",
      "714/559050 (epoch 0), train_loss = 6.825, time/batch = 0.082\n",
      "716/559050 (epoch 0), train_loss = 7.743, time/batch = 0.082\n",
      "718/559050 (epoch 0), train_loss = 7.204, time/batch = 0.081\n",
      "720/559050 (epoch 0), train_loss = 6.676, time/batch = 0.081\n",
      "722/559050 (epoch 0), train_loss = 7.006, time/batch = 0.084\n",
      "724/559050 (epoch 0), train_loss = 6.318, time/batch = 0.083\n",
      "726/559050 (epoch 0), train_loss = 7.677, time/batch = 0.083\n",
      "728/559050 (epoch 0), train_loss = 8.092, time/batch = 0.081\n",
      "730/559050 (epoch 0), train_loss = 6.639, time/batch = 0.080\n",
      "732/559050 (epoch 0), train_loss = 7.065, time/batch = 0.081\n",
      "734/559050 (epoch 0), train_loss = 7.605, time/batch = 0.085\n",
      "736/559050 (epoch 0), train_loss = 6.865, time/batch = 0.084\n",
      "738/559050 (epoch 0), train_loss = 6.882, time/batch = 0.084\n",
      "740/559050 (epoch 0), train_loss = 8.408, time/batch = 0.082\n",
      "742/559050 (epoch 0), train_loss = 6.431, time/batch = 0.082\n",
      "744/559050 (epoch 0), train_loss = 9.093, time/batch = 0.083\n",
      "746/559050 (epoch 0), train_loss = 7.138, time/batch = 0.082\n",
      "748/559050 (epoch 0), train_loss = 7.331, time/batch = 0.082\n",
      "750/559050 (epoch 0), train_loss = 6.780, time/batch = 0.083\n",
      "752/559050 (epoch 0), train_loss = 8.538, time/batch = 0.083\n",
      "754/559050 (epoch 0), train_loss = 7.013, time/batch = 0.082\n",
      "756/559050 (epoch 0), train_loss = 7.272, time/batch = 0.084\n",
      "758/559050 (epoch 0), train_loss = 8.077, time/batch = 0.084\n",
      "760/559050 (epoch 0), train_loss = 6.908, time/batch = 0.083\n",
      "762/559050 (epoch 0), train_loss = 7.596, time/batch = 0.081\n",
      "764/559050 (epoch 0), train_loss = 8.597, time/batch = 0.083\n",
      "766/559050 (epoch 0), train_loss = 7.230, time/batch = 0.083\n",
      "768/559050 (epoch 0), train_loss = 7.275, time/batch = 0.081\n",
      "770/559050 (epoch 0), train_loss = 7.409, time/batch = 0.083\n",
      "772/559050 (epoch 0), train_loss = 7.063, time/batch = 0.081\n",
      "774/559050 (epoch 0), train_loss = 6.846, time/batch = 0.082\n",
      "776/559050 (epoch 0), train_loss = 6.676, time/batch = 0.083\n",
      "778/559050 (epoch 0), train_loss = 6.805, time/batch = 0.082\n",
      "780/559050 (epoch 0), train_loss = 8.800, time/batch = 0.082\n",
      "782/559050 (epoch 0), train_loss = 8.118, time/batch = 0.081\n",
      "784/559050 (epoch 0), train_loss = 7.668, time/batch = 0.082\n",
      "786/559050 (epoch 0), train_loss = 7.731, time/batch = 0.082\n",
      "788/559050 (epoch 0), train_loss = 5.920, time/batch = 0.082\n",
      "790/559050 (epoch 0), train_loss = 5.686, time/batch = 0.082\n",
      "792/559050 (epoch 0), train_loss = 5.704, time/batch = 0.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/559050 (epoch 0), train_loss = 5.766, time/batch = 0.083\n",
      "796/559050 (epoch 0), train_loss = 6.477, time/batch = 0.082\n",
      "798/559050 (epoch 0), train_loss = 6.809, time/batch = 0.082\n",
      "800/559050 (epoch 0), train_loss = 6.330, time/batch = 0.079\n",
      "802/559050 (epoch 0), train_loss = 6.629, time/batch = 0.082\n",
      "804/559050 (epoch 0), train_loss = 6.622, time/batch = 0.082\n",
      "806/559050 (epoch 0), train_loss = 5.787, time/batch = 0.081\n",
      "808/559050 (epoch 0), train_loss = 6.050, time/batch = 0.082\n",
      "810/559050 (epoch 0), train_loss = 7.565, time/batch = 0.082\n",
      "812/559050 (epoch 0), train_loss = 5.625, time/batch = 0.078\n",
      "814/559050 (epoch 0), train_loss = 5.828, time/batch = 0.080\n",
      "816/559050 (epoch 0), train_loss = 4.837, time/batch = 0.080\n",
      "818/559050 (epoch 0), train_loss = 6.746, time/batch = 0.088\n",
      "820/559050 (epoch 0), train_loss = 6.625, time/batch = 0.084\n",
      "822/559050 (epoch 0), train_loss = 7.664, time/batch = 0.077\n",
      "824/559050 (epoch 0), train_loss = 8.133, time/batch = 0.079\n",
      "826/559050 (epoch 0), train_loss = 5.618, time/batch = 0.090\n",
      "828/559050 (epoch 0), train_loss = 6.490, time/batch = 0.082\n",
      "830/559050 (epoch 0), train_loss = 7.076, time/batch = 0.083\n",
      "832/559050 (epoch 0), train_loss = 6.603, time/batch = 0.079\n",
      "834/559050 (epoch 0), train_loss = 8.534, time/batch = 0.081\n",
      "836/559050 (epoch 0), train_loss = 7.010, time/batch = 0.083\n",
      "838/559050 (epoch 0), train_loss = 7.147, time/batch = 0.081\n",
      "840/559050 (epoch 0), train_loss = 6.645, time/batch = 0.081\n",
      "842/559050 (epoch 0), train_loss = 7.414, time/batch = 0.081\n",
      "844/559050 (epoch 0), train_loss = 5.419, time/batch = 0.078\n",
      "846/559050 (epoch 0), train_loss = 6.326, time/batch = 0.083\n",
      "848/559050 (epoch 0), train_loss = 5.670, time/batch = 0.082\n",
      "850/559050 (epoch 0), train_loss = 6.278, time/batch = 0.081\n",
      "852/559050 (epoch 0), train_loss = 6.359, time/batch = 0.081\n",
      "854/559050 (epoch 0), train_loss = 5.307, time/batch = 0.080\n",
      "856/559050 (epoch 0), train_loss = 7.086, time/batch = 0.081\n",
      "858/559050 (epoch 0), train_loss = 6.858, time/batch = 0.080\n",
      "860/559050 (epoch 0), train_loss = 5.581, time/batch = 0.080\n",
      "862/559050 (epoch 0), train_loss = 5.826, time/batch = 0.081\n",
      "864/559050 (epoch 0), train_loss = 5.915, time/batch = 0.082\n",
      "866/559050 (epoch 0), train_loss = 5.806, time/batch = 0.082\n",
      "868/559050 (epoch 0), train_loss = 6.913, time/batch = 0.081\n",
      "870/559050 (epoch 0), train_loss = 7.509, time/batch = 0.077\n",
      "872/559050 (epoch 0), train_loss = 6.443, time/batch = 0.080\n",
      "874/559050 (epoch 0), train_loss = 7.099, time/batch = 0.081\n",
      "876/559050 (epoch 0), train_loss = 6.074, time/batch = 0.079\n",
      "878/559050 (epoch 0), train_loss = 5.844, time/batch = 0.080\n",
      "880/559050 (epoch 0), train_loss = 5.901, time/batch = 0.081\n",
      "882/559050 (epoch 0), train_loss = 7.788, time/batch = 0.081\n",
      "884/559050 (epoch 0), train_loss = 7.013, time/batch = 0.080\n",
      "886/559050 (epoch 0), train_loss = 7.038, time/batch = 0.079\n",
      "888/559050 (epoch 0), train_loss = 5.968, time/batch = 0.079\n",
      "890/559050 (epoch 0), train_loss = 7.869, time/batch = 0.079\n",
      "892/559050 (epoch 0), train_loss = 6.955, time/batch = 0.079\n",
      "894/559050 (epoch 0), train_loss = 6.198, time/batch = 0.080\n",
      "896/559050 (epoch 0), train_loss = 7.163, time/batch = 0.081\n",
      "898/559050 (epoch 0), train_loss = 6.793, time/batch = 0.080\n",
      "900/559050 (epoch 0), train_loss = 7.123, time/batch = 0.082\n",
      "902/559050 (epoch 0), train_loss = 7.303, time/batch = 0.081\n",
      "904/559050 (epoch 0), train_loss = 6.035, time/batch = 0.080\n",
      "906/559050 (epoch 0), train_loss = 7.583, time/batch = 0.080\n",
      "908/559050 (epoch 0), train_loss = 6.888, time/batch = 0.080\n",
      "910/559050 (epoch 0), train_loss = 6.390, time/batch = 0.081\n",
      "912/559050 (epoch 0), train_loss = 6.593, time/batch = 0.083\n",
      "914/559050 (epoch 0), train_loss = 6.928, time/batch = 0.082\n",
      "916/559050 (epoch 0), train_loss = 7.202, time/batch = 0.096\n",
      "918/559050 (epoch 0), train_loss = 7.065, time/batch = 0.094\n",
      "920/559050 (epoch 0), train_loss = 6.172, time/batch = 0.086\n",
      "922/559050 (epoch 0), train_loss = 6.241, time/batch = 0.087\n",
      "924/559050 (epoch 0), train_loss = 5.933, time/batch = 0.087\n",
      "926/559050 (epoch 0), train_loss = 6.167, time/batch = 0.088\n",
      "928/559050 (epoch 0), train_loss = 7.419, time/batch = 0.089\n",
      "930/559050 (epoch 0), train_loss = 8.101, time/batch = 0.085\n",
      "932/559050 (epoch 0), train_loss = 7.563, time/batch = 0.089\n",
      "934/559050 (epoch 0), train_loss = 5.846, time/batch = 0.085\n",
      "936/559050 (epoch 0), train_loss = 6.934, time/batch = 0.088\n",
      "938/559050 (epoch 0), train_loss = 6.495, time/batch = 0.085\n",
      "940/559050 (epoch 0), train_loss = 7.639, time/batch = 0.088\n",
      "942/559050 (epoch 0), train_loss = 6.406, time/batch = 0.086\n",
      "944/559050 (epoch 0), train_loss = 6.956, time/batch = 0.087\n",
      "946/559050 (epoch 0), train_loss = 5.438, time/batch = 0.088\n",
      "948/559050 (epoch 0), train_loss = 6.826, time/batch = 0.089\n",
      "950/559050 (epoch 0), train_loss = 7.240, time/batch = 0.086\n",
      "952/559050 (epoch 0), train_loss = 5.560, time/batch = 0.081\n",
      "954/559050 (epoch 0), train_loss = 6.232, time/batch = 0.079\n",
      "956/559050 (epoch 0), train_loss = 6.254, time/batch = 0.080\n",
      "958/559050 (epoch 0), train_loss = 6.482, time/batch = 0.080\n",
      "960/559050 (epoch 0), train_loss = 6.341, time/batch = 0.081\n",
      "962/559050 (epoch 0), train_loss = 5.554, time/batch = 0.082\n",
      "964/559050 (epoch 0), train_loss = 7.131, time/batch = 0.081\n",
      "966/559050 (epoch 0), train_loss = 5.973, time/batch = 0.083\n",
      "968/559050 (epoch 0), train_loss = 6.132, time/batch = 0.081\n",
      "970/559050 (epoch 0), train_loss = 6.988, time/batch = 0.082\n",
      "972/559050 (epoch 0), train_loss = 9.788, time/batch = 0.084\n",
      "974/559050 (epoch 0), train_loss = 6.449, time/batch = 0.081\n",
      "976/559050 (epoch 0), train_loss = 7.625, time/batch = 0.081\n",
      "978/559050 (epoch 0), train_loss = 6.383, time/batch = 0.082\n",
      "980/559050 (epoch 0), train_loss = 6.576, time/batch = 0.080\n",
      "982/559050 (epoch 0), train_loss = 6.094, time/batch = 0.082\n",
      "984/559050 (epoch 0), train_loss = 6.056, time/batch = 0.083\n",
      "986/559050 (epoch 0), train_loss = 6.894, time/batch = 0.081\n",
      "988/559050 (epoch 0), train_loss = 7.511, time/batch = 0.082\n",
      "990/559050 (epoch 0), train_loss = 6.050, time/batch = 0.082\n",
      "992/559050 (epoch 0), train_loss = 7.339, time/batch = 0.079\n",
      "994/559050 (epoch 0), train_loss = 6.096, time/batch = 0.079\n",
      "996/559050 (epoch 0), train_loss = 7.009, time/batch = 0.083\n",
      "998/559050 (epoch 0), train_loss = 8.252, time/batch = 0.081\n",
      "1000/559050 (epoch 0), train_loss = 6.373, time/batch = 0.081\n",
      "1002/559050 (epoch 0), train_loss = 7.911, time/batch = 0.084\n",
      "1004/559050 (epoch 0), train_loss = 7.611, time/batch = 0.083\n",
      "1006/559050 (epoch 0), train_loss = 6.581, time/batch = 0.082\n",
      "1008/559050 (epoch 0), train_loss = 7.594, time/batch = 0.081\n",
      "1010/559050 (epoch 0), train_loss = 7.173, time/batch = 0.083\n",
      "1012/559050 (epoch 0), train_loss = 6.606, time/batch = 0.080\n",
      "1014/559050 (epoch 0), train_loss = 6.950, time/batch = 0.081\n",
      "1016/559050 (epoch 0), train_loss = 6.330, time/batch = 0.082\n",
      "1018/559050 (epoch 0), train_loss = 8.270, time/batch = 0.083\n",
      "1020/559050 (epoch 0), train_loss = 7.929, time/batch = 0.082\n",
      "1022/559050 (epoch 0), train_loss = 7.106, time/batch = 0.081\n",
      "1024/559050 (epoch 0), train_loss = 7.453, time/batch = 0.083\n",
      "1026/559050 (epoch 0), train_loss = 6.003, time/batch = 0.085\n",
      "1028/559050 (epoch 0), train_loss = 6.421, time/batch = 0.082\n",
      "1030/559050 (epoch 0), train_loss = 6.114, time/batch = 0.080\n",
      "1032/559050 (epoch 0), train_loss = 6.640, time/batch = 0.082\n",
      "1034/559050 (epoch 0), train_loss = 7.477, time/batch = 0.081\n",
      "1036/559050 (epoch 0), train_loss = 6.263, time/batch = 0.082\n",
      "1038/559050 (epoch 0), train_loss = 6.799, time/batch = 0.083\n",
      "1040/559050 (epoch 0), train_loss = 8.281, time/batch = 0.081\n",
      "1042/559050 (epoch 0), train_loss = 7.073, time/batch = 0.082\n",
      "1044/559050 (epoch 0), train_loss = 7.686, time/batch = 0.082\n",
      "1046/559050 (epoch 0), train_loss = 6.516, time/batch = 0.083\n",
      "1048/559050 (epoch 0), train_loss = 7.060, time/batch = 0.080\n",
      "1050/559050 (epoch 0), train_loss = 6.954, time/batch = 0.080\n",
      "1052/559050 (epoch 0), train_loss = 5.873, time/batch = 0.081\n",
      "1054/559050 (epoch 0), train_loss = 8.439, time/batch = 0.082\n",
      "1056/559050 (epoch 0), train_loss = 6.969, time/batch = 0.083\n",
      "1058/559050 (epoch 0), train_loss = 6.305, time/batch = 0.081\n",
      "1060/559050 (epoch 0), train_loss = 8.560, time/batch = 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062/559050 (epoch 0), train_loss = 6.703, time/batch = 0.083\n",
      "1064/559050 (epoch 0), train_loss = 7.770, time/batch = 0.080\n",
      "1066/559050 (epoch 0), train_loss = 6.899, time/batch = 0.083\n",
      "1068/559050 (epoch 0), train_loss = 7.084, time/batch = 0.081\n",
      "1070/559050 (epoch 0), train_loss = 5.838, time/batch = 0.082\n",
      "1072/559050 (epoch 0), train_loss = 8.040, time/batch = 0.082\n",
      "1074/559050 (epoch 0), train_loss = 8.320, time/batch = 0.082\n",
      "1076/559050 (epoch 0), train_loss = 6.019, time/batch = 0.082\n",
      "1078/559050 (epoch 0), train_loss = 6.339, time/batch = 0.081\n",
      "1080/559050 (epoch 0), train_loss = 6.132, time/batch = 0.082\n",
      "1082/559050 (epoch 0), train_loss = 6.522, time/batch = 0.081\n",
      "1084/559050 (epoch 0), train_loss = 6.171, time/batch = 0.081\n",
      "1086/559050 (epoch 0), train_loss = 6.774, time/batch = 0.081\n",
      "1088/559050 (epoch 0), train_loss = 7.286, time/batch = 0.081\n",
      "1090/559050 (epoch 0), train_loss = 6.594, time/batch = 0.080\n",
      "1092/559050 (epoch 0), train_loss = 7.906, time/batch = 0.081\n",
      "1094/559050 (epoch 0), train_loss = 6.368, time/batch = 0.080\n",
      "1096/559050 (epoch 0), train_loss = 6.712, time/batch = 0.080\n",
      "1098/559050 (epoch 0), train_loss = 5.923, time/batch = 0.080\n",
      "1100/559050 (epoch 0), train_loss = 6.529, time/batch = 0.081\n",
      "1102/559050 (epoch 0), train_loss = 6.813, time/batch = 0.084\n",
      "1104/559050 (epoch 0), train_loss = 7.209, time/batch = 0.083\n",
      "1106/559050 (epoch 0), train_loss = 5.860, time/batch = 0.081\n",
      "1108/559050 (epoch 0), train_loss = 7.203, time/batch = 0.079\n",
      "1110/559050 (epoch 0), train_loss = 7.509, time/batch = 0.081\n",
      "1112/559050 (epoch 0), train_loss = 7.118, time/batch = 0.080\n",
      "1114/559050 (epoch 0), train_loss = 6.480, time/batch = 0.082\n",
      "1116/559050 (epoch 0), train_loss = 7.846, time/batch = 0.083\n",
      "1118/559050 (epoch 0), train_loss = 5.176, time/batch = 0.084\n",
      "1120/559050 (epoch 0), train_loss = 6.399, time/batch = 0.082\n",
      "1122/559050 (epoch 0), train_loss = 5.845, time/batch = 0.083\n",
      "1124/559050 (epoch 0), train_loss = 6.230, time/batch = 0.081\n",
      "1126/559050 (epoch 0), train_loss = 5.872, time/batch = 0.083\n",
      "1128/559050 (epoch 0), train_loss = 6.174, time/batch = 0.081\n",
      "1130/559050 (epoch 0), train_loss = 6.474, time/batch = 0.080\n",
      "1132/559050 (epoch 0), train_loss = 7.324, time/batch = 0.082\n",
      "1134/559050 (epoch 0), train_loss = 6.585, time/batch = 0.080\n",
      "1136/559050 (epoch 0), train_loss = 6.134, time/batch = 0.084\n",
      "1138/559050 (epoch 0), train_loss = 7.445, time/batch = 0.081\n",
      "1140/559050 (epoch 0), train_loss = 5.598, time/batch = 0.081\n",
      "1142/559050 (epoch 0), train_loss = 6.128, time/batch = 0.086\n",
      "1144/559050 (epoch 0), train_loss = 7.721, time/batch = 0.081\n",
      "1146/559050 (epoch 0), train_loss = 6.832, time/batch = 0.081\n",
      "1148/559050 (epoch 0), train_loss = 7.080, time/batch = 0.083\n",
      "1150/559050 (epoch 0), train_loss = 5.427, time/batch = 0.083\n",
      "1152/559050 (epoch 0), train_loss = 6.287, time/batch = 0.081\n",
      "1154/559050 (epoch 0), train_loss = 6.241, time/batch = 0.084\n",
      "1156/559050 (epoch 0), train_loss = 7.322, time/batch = 0.081\n",
      "1158/559050 (epoch 0), train_loss = 6.953, time/batch = 0.081\n",
      "1160/559050 (epoch 0), train_loss = 4.907, time/batch = 0.082\n",
      "1162/559050 (epoch 0), train_loss = 5.993, time/batch = 0.081\n",
      "1164/559050 (epoch 0), train_loss = 8.137, time/batch = 0.083\n",
      "1166/559050 (epoch 0), train_loss = 5.666, time/batch = 0.080\n",
      "1168/559050 (epoch 0), train_loss = 7.017, time/batch = 0.082\n",
      "1170/559050 (epoch 0), train_loss = 6.901, time/batch = 0.084\n",
      "1172/559050 (epoch 0), train_loss = 6.708, time/batch = 0.082\n",
      "1174/559050 (epoch 0), train_loss = 6.693, time/batch = 0.080\n",
      "1176/559050 (epoch 0), train_loss = 6.252, time/batch = 0.081\n",
      "1178/559050 (epoch 0), train_loss = 7.390, time/batch = 0.080\n",
      "1180/559050 (epoch 0), train_loss = 7.043, time/batch = 0.083\n",
      "1182/559050 (epoch 0), train_loss = 5.958, time/batch = 0.081\n",
      "1184/559050 (epoch 0), train_loss = 6.100, time/batch = 0.082\n",
      "1186/559050 (epoch 0), train_loss = 7.339, time/batch = 0.081\n",
      "1188/559050 (epoch 0), train_loss = 6.103, time/batch = 0.080\n",
      "1190/559050 (epoch 0), train_loss = 8.256, time/batch = 0.083\n",
      "1192/559050 (epoch 0), train_loss = 6.877, time/batch = 0.083\n",
      "1194/559050 (epoch 0), train_loss = 6.386, time/batch = 0.081\n",
      "1196/559050 (epoch 0), train_loss = 6.384, time/batch = 0.082\n",
      "1198/559050 (epoch 0), train_loss = 5.943, time/batch = 0.082\n",
      "1200/559050 (epoch 0), train_loss = 7.889, time/batch = 0.081\n",
      "1202/559050 (epoch 0), train_loss = 6.220, time/batch = 0.084\n",
      "1204/559050 (epoch 0), train_loss = 6.640, time/batch = 0.082\n",
      "1206/559050 (epoch 0), train_loss = 7.398, time/batch = 0.081\n",
      "1208/559050 (epoch 0), train_loss = 7.500, time/batch = 0.082\n",
      "1210/559050 (epoch 0), train_loss = 7.533, time/batch = 0.081\n",
      "1212/559050 (epoch 0), train_loss = 7.871, time/batch = 0.080\n",
      "1214/559050 (epoch 0), train_loss = 6.677, time/batch = 0.082\n",
      "1216/559050 (epoch 0), train_loss = 8.428, time/batch = 0.080\n",
      "1218/559050 (epoch 0), train_loss = 6.845, time/batch = 0.081\n",
      "1220/559050 (epoch 0), train_loss = 6.671, time/batch = 0.083\n",
      "1222/559050 (epoch 0), train_loss = 5.481, time/batch = 0.081\n",
      "1224/559050 (epoch 0), train_loss = 4.949, time/batch = 0.081\n",
      "1226/559050 (epoch 0), train_loss = 7.400, time/batch = 0.084\n",
      "1228/559050 (epoch 0), train_loss = 7.202, time/batch = 0.080\n",
      "1230/559050 (epoch 0), train_loss = 6.565, time/batch = 0.082\n",
      "1232/559050 (epoch 0), train_loss = 7.317, time/batch = 0.082\n",
      "1234/559050 (epoch 0), train_loss = 7.373, time/batch = 0.081\n",
      "1236/559050 (epoch 0), train_loss = 6.861, time/batch = 0.081\n",
      "1238/559050 (epoch 0), train_loss = 6.530, time/batch = 0.082\n",
      "1240/559050 (epoch 0), train_loss = 5.923, time/batch = 0.081\n",
      "1242/559050 (epoch 0), train_loss = 5.234, time/batch = 0.083\n",
      "1244/559050 (epoch 0), train_loss = 6.049, time/batch = 0.080\n",
      "1246/559050 (epoch 0), train_loss = 5.291, time/batch = 0.082\n",
      "1248/559050 (epoch 0), train_loss = 6.514, time/batch = 0.080\n",
      "1250/559050 (epoch 0), train_loss = 7.062, time/batch = 0.082\n",
      "1252/559050 (epoch 0), train_loss = 6.418, time/batch = 0.081\n",
      "1254/559050 (epoch 0), train_loss = 6.613, time/batch = 0.082\n",
      "1256/559050 (epoch 0), train_loss = 6.710, time/batch = 0.080\n",
      "1258/559050 (epoch 0), train_loss = 6.615, time/batch = 0.083\n",
      "1260/559050 (epoch 0), train_loss = 6.906, time/batch = 0.080\n",
      "1262/559050 (epoch 0), train_loss = 5.513, time/batch = 0.080\n",
      "1264/559050 (epoch 0), train_loss = 4.893, time/batch = 0.082\n",
      "1266/559050 (epoch 0), train_loss = 7.188, time/batch = 0.082\n",
      "1268/559050 (epoch 0), train_loss = 6.040, time/batch = 0.081\n",
      "1270/559050 (epoch 0), train_loss = 5.953, time/batch = 0.084\n",
      "1272/559050 (epoch 0), train_loss = 7.185, time/batch = 0.082\n",
      "1274/559050 (epoch 0), train_loss = 5.592, time/batch = 0.081\n",
      "1276/559050 (epoch 0), train_loss = 5.566, time/batch = 0.083\n",
      "1278/559050 (epoch 0), train_loss = 6.886, time/batch = 0.082\n",
      "1280/559050 (epoch 0), train_loss = 6.103, time/batch = 0.082\n",
      "1282/559050 (epoch 0), train_loss = 5.832, time/batch = 0.082\n",
      "1284/559050 (epoch 0), train_loss = 6.851, time/batch = 0.082\n",
      "1286/559050 (epoch 0), train_loss = 6.264, time/batch = 0.083\n",
      "1288/559050 (epoch 0), train_loss = 6.056, time/batch = 0.081\n",
      "1290/559050 (epoch 0), train_loss = 8.336, time/batch = 0.080\n",
      "1292/559050 (epoch 0), train_loss = 6.415, time/batch = 0.082\n",
      "1294/559050 (epoch 0), train_loss = 7.519, time/batch = 0.081\n",
      "1296/559050 (epoch 0), train_loss = 6.544, time/batch = 0.082\n",
      "1298/559050 (epoch 0), train_loss = 6.891, time/batch = 0.082\n",
      "1300/559050 (epoch 0), train_loss = 6.192, time/batch = 0.080\n",
      "1302/559050 (epoch 0), train_loss = 6.651, time/batch = 0.079\n",
      "1304/559050 (epoch 0), train_loss = 6.688, time/batch = 0.081\n",
      "1306/559050 (epoch 0), train_loss = 7.038, time/batch = 0.082\n",
      "1308/559050 (epoch 0), train_loss = 7.477, time/batch = 0.081\n",
      "1310/559050 (epoch 0), train_loss = 5.211, time/batch = 0.082\n",
      "1312/559050 (epoch 0), train_loss = 7.308, time/batch = 0.081\n",
      "1314/559050 (epoch 0), train_loss = 5.035, time/batch = 0.082\n",
      "1316/559050 (epoch 0), train_loss = 5.814, time/batch = 0.082\n",
      "1318/559050 (epoch 0), train_loss = 6.170, time/batch = 0.083\n",
      "1320/559050 (epoch 0), train_loss = 7.886, time/batch = 0.083\n",
      "1322/559050 (epoch 0), train_loss = 5.942, time/batch = 0.082\n",
      "1324/559050 (epoch 0), train_loss = 6.769, time/batch = 0.082\n",
      "1326/559050 (epoch 0), train_loss = 5.961, time/batch = 0.082\n",
      "1328/559050 (epoch 0), train_loss = 5.337, time/batch = 0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330/559050 (epoch 0), train_loss = 4.873, time/batch = 0.082\n",
      "1332/559050 (epoch 0), train_loss = 6.083, time/batch = 0.082\n",
      "1334/559050 (epoch 0), train_loss = 7.442, time/batch = 0.082\n",
      "1336/559050 (epoch 0), train_loss = 5.981, time/batch = 0.082\n",
      "1338/559050 (epoch 0), train_loss = 7.396, time/batch = 0.083\n",
      "1340/559050 (epoch 0), train_loss = 7.263, time/batch = 0.081\n",
      "1342/559050 (epoch 0), train_loss = 8.792, time/batch = 0.082\n",
      "1344/559050 (epoch 0), train_loss = 7.134, time/batch = 0.081\n",
      "1346/559050 (epoch 0), train_loss = 7.447, time/batch = 0.081\n",
      "1348/559050 (epoch 0), train_loss = 7.427, time/batch = 0.081\n",
      "1350/559050 (epoch 0), train_loss = 6.103, time/batch = 0.082\n",
      "1352/559050 (epoch 0), train_loss = 5.992, time/batch = 0.083\n",
      "1354/559050 (epoch 0), train_loss = 6.817, time/batch = 0.081\n",
      "1356/559050 (epoch 0), train_loss = 8.152, time/batch = 0.079\n",
      "1358/559050 (epoch 0), train_loss = 6.455, time/batch = 0.081\n",
      "1360/559050 (epoch 0), train_loss = 7.579, time/batch = 0.079\n",
      "1362/559050 (epoch 0), train_loss = 6.808, time/batch = 0.082\n",
      "1364/559050 (epoch 0), train_loss = 8.201, time/batch = 0.081\n",
      "1366/559050 (epoch 0), train_loss = 6.745, time/batch = 0.078\n",
      "1368/559050 (epoch 0), train_loss = 6.668, time/batch = 0.082\n",
      "1370/559050 (epoch 0), train_loss = 7.045, time/batch = 0.079\n",
      "1372/559050 (epoch 0), train_loss = 7.747, time/batch = 0.081\n",
      "1374/559050 (epoch 0), train_loss = 7.796, time/batch = 0.081\n",
      "1376/559050 (epoch 0), train_loss = 5.951, time/batch = 0.078\n",
      "1378/559050 (epoch 0), train_loss = 8.236, time/batch = 0.080\n",
      "1380/559050 (epoch 0), train_loss = 5.774, time/batch = 0.080\n",
      "1382/559050 (epoch 0), train_loss = 5.447, time/batch = 0.080\n",
      "1384/559050 (epoch 0), train_loss = 6.456, time/batch = 0.082\n",
      "1386/559050 (epoch 0), train_loss = 6.752, time/batch = 0.080\n",
      "1388/559050 (epoch 0), train_loss = 6.260, time/batch = 0.079\n",
      "1390/559050 (epoch 0), train_loss = 8.041, time/batch = 0.079\n",
      "1392/559050 (epoch 0), train_loss = 6.954, time/batch = 0.080\n",
      "1394/559050 (epoch 0), train_loss = 6.940, time/batch = 0.081\n",
      "1396/559050 (epoch 0), train_loss = 6.673, time/batch = 0.082\n",
      "1398/559050 (epoch 0), train_loss = 5.587, time/batch = 0.079\n",
      "1400/559050 (epoch 0), train_loss = 6.235, time/batch = 0.080\n",
      "1402/559050 (epoch 0), train_loss = 6.846, time/batch = 0.080\n",
      "1404/559050 (epoch 0), train_loss = 6.483, time/batch = 0.080\n",
      "1406/559050 (epoch 0), train_loss = 6.672, time/batch = 0.082\n",
      "1408/559050 (epoch 0), train_loss = 6.138, time/batch = 0.079\n",
      "1410/559050 (epoch 0), train_loss = 7.999, time/batch = 0.079\n",
      "1412/559050 (epoch 0), train_loss = 6.678, time/batch = 0.082\n",
      "1414/559050 (epoch 0), train_loss = 9.557, time/batch = 0.081\n",
      "1416/559050 (epoch 0), train_loss = 6.612, time/batch = 0.080\n",
      "1418/559050 (epoch 0), train_loss = 6.618, time/batch = 0.079\n",
      "1420/559050 (epoch 0), train_loss = 7.109, time/batch = 0.082\n",
      "1422/559050 (epoch 0), train_loss = 7.017, time/batch = 0.082\n",
      "1424/559050 (epoch 0), train_loss = 7.211, time/batch = 0.081\n",
      "1426/559050 (epoch 0), train_loss = 6.399, time/batch = 0.082\n",
      "1428/559050 (epoch 0), train_loss = 6.972, time/batch = 0.082\n",
      "1430/559050 (epoch 0), train_loss = 6.377, time/batch = 0.084\n",
      "1432/559050 (epoch 0), train_loss = 7.164, time/batch = 0.081\n",
      "1434/559050 (epoch 0), train_loss = 7.297, time/batch = 0.082\n",
      "1436/559050 (epoch 0), train_loss = 7.229, time/batch = 0.082\n",
      "1438/559050 (epoch 0), train_loss = 7.393, time/batch = 0.081\n",
      "1440/559050 (epoch 0), train_loss = 7.071, time/batch = 0.081\n",
      "1442/559050 (epoch 0), train_loss = 7.435, time/batch = 0.083\n",
      "1444/559050 (epoch 0), train_loss = 7.046, time/batch = 0.080\n",
      "1446/559050 (epoch 0), train_loss = 6.207, time/batch = 0.080\n",
      "1448/559050 (epoch 0), train_loss = 6.392, time/batch = 0.083\n",
      "1450/559050 (epoch 0), train_loss = 8.329, time/batch = 0.080\n",
      "1452/559050 (epoch 0), train_loss = 6.766, time/batch = 0.080\n",
      "1454/559050 (epoch 0), train_loss = 5.877, time/batch = 0.080\n",
      "1456/559050 (epoch 0), train_loss = 6.093, time/batch = 0.082\n",
      "1458/559050 (epoch 0), train_loss = 7.056, time/batch = 0.079\n",
      "1460/559050 (epoch 0), train_loss = 7.206, time/batch = 0.081\n",
      "1462/559050 (epoch 0), train_loss = 6.280, time/batch = 0.081\n",
      "1464/559050 (epoch 0), train_loss = 6.360, time/batch = 0.079\n",
      "1466/559050 (epoch 0), train_loss = 7.256, time/batch = 0.081\n",
      "1468/559050 (epoch 0), train_loss = 7.500, time/batch = 0.080\n",
      "1470/559050 (epoch 0), train_loss = 7.135, time/batch = 0.081\n",
      "1472/559050 (epoch 0), train_loss = 6.465, time/batch = 0.081\n",
      "1474/559050 (epoch 0), train_loss = 6.840, time/batch = 0.079\n",
      "1476/559050 (epoch 0), train_loss = 6.773, time/batch = 0.081\n",
      "1478/559050 (epoch 0), train_loss = 5.489, time/batch = 0.083\n",
      "1480/559050 (epoch 0), train_loss = 6.120, time/batch = 0.082\n",
      "1482/559050 (epoch 0), train_loss = 5.849, time/batch = 0.082\n",
      "1484/559050 (epoch 0), train_loss = 7.289, time/batch = 0.082\n",
      "1486/559050 (epoch 0), train_loss = 7.738, time/batch = 0.083\n",
      "1488/559050 (epoch 0), train_loss = 7.489, time/batch = 0.081\n",
      "1490/559050 (epoch 0), train_loss = 7.701, time/batch = 0.082\n",
      "1492/559050 (epoch 0), train_loss = 6.589, time/batch = 0.082\n",
      "1494/559050 (epoch 0), train_loss = 7.097, time/batch = 0.083\n",
      "1496/559050 (epoch 0), train_loss = 6.157, time/batch = 0.083\n",
      "1498/559050 (epoch 0), train_loss = 8.340, time/batch = 0.081\n",
      "1500/559050 (epoch 0), train_loss = 8.597, time/batch = 0.080\n",
      "1502/559050 (epoch 0), train_loss = 6.381, time/batch = 0.081\n",
      "1504/559050 (epoch 0), train_loss = 7.804, time/batch = 0.084\n",
      "1506/559050 (epoch 0), train_loss = 6.854, time/batch = 0.082\n",
      "1508/559050 (epoch 0), train_loss = 6.615, time/batch = 0.082\n",
      "1510/559050 (epoch 0), train_loss = 6.176, time/batch = 0.083\n",
      "1512/559050 (epoch 0), train_loss = 7.177, time/batch = 0.081\n",
      "1514/559050 (epoch 0), train_loss = 6.593, time/batch = 0.082\n",
      "1516/559050 (epoch 0), train_loss = 6.890, time/batch = 0.084\n",
      "1518/559050 (epoch 0), train_loss = 7.518, time/batch = 0.083\n",
      "1520/559050 (epoch 0), train_loss = 6.250, time/batch = 0.081\n",
      "1522/559050 (epoch 0), train_loss = 7.776, time/batch = 0.082\n",
      "1524/559050 (epoch 0), train_loss = 7.376, time/batch = 0.080\n",
      "1526/559050 (epoch 0), train_loss = 6.649, time/batch = 0.082\n",
      "1528/559050 (epoch 0), train_loss = 6.950, time/batch = 0.083\n",
      "1530/559050 (epoch 0), train_loss = 6.741, time/batch = 0.081\n",
      "1532/559050 (epoch 0), train_loss = 6.532, time/batch = 0.083\n",
      "1534/559050 (epoch 0), train_loss = 6.502, time/batch = 0.082\n",
      "1536/559050 (epoch 0), train_loss = 7.272, time/batch = 0.083\n",
      "1538/559050 (epoch 0), train_loss = 7.415, time/batch = 0.081\n",
      "1540/559050 (epoch 0), train_loss = 8.000, time/batch = 0.081\n",
      "1542/559050 (epoch 0), train_loss = 6.161, time/batch = 0.081\n",
      "1544/559050 (epoch 0), train_loss = 6.120, time/batch = 0.082\n",
      "1546/559050 (epoch 0), train_loss = 6.814, time/batch = 0.080\n",
      "1548/559050 (epoch 0), train_loss = 6.838, time/batch = 0.081\n",
      "1550/559050 (epoch 0), train_loss = 6.701, time/batch = 0.083\n",
      "1552/559050 (epoch 0), train_loss = 6.110, time/batch = 0.082\n",
      "1554/559050 (epoch 0), train_loss = 5.602, time/batch = 0.082\n",
      "1556/559050 (epoch 0), train_loss = 5.536, time/batch = 0.082\n",
      "1558/559050 (epoch 0), train_loss = 6.069, time/batch = 0.079\n",
      "1560/559050 (epoch 0), train_loss = 6.402, time/batch = 0.082\n",
      "1562/559050 (epoch 0), train_loss = 5.969, time/batch = 0.083\n",
      "1564/559050 (epoch 0), train_loss = 7.729, time/batch = 0.083\n",
      "1566/559050 (epoch 0), train_loss = 6.765, time/batch = 0.082\n",
      "1568/559050 (epoch 0), train_loss = 5.771, time/batch = 0.081\n",
      "1570/559050 (epoch 0), train_loss = 6.598, time/batch = 0.082\n",
      "1572/559050 (epoch 0), train_loss = 6.431, time/batch = 0.082\n",
      "1574/559050 (epoch 0), train_loss = 6.194, time/batch = 0.082\n",
      "1576/559050 (epoch 0), train_loss = 5.848, time/batch = 0.082\n",
      "1578/559050 (epoch 0), train_loss = 6.512, time/batch = 0.081\n",
      "1580/559050 (epoch 0), train_loss = 6.595, time/batch = 0.082\n",
      "1582/559050 (epoch 0), train_loss = 6.238, time/batch = 0.082\n",
      "1584/559050 (epoch 0), train_loss = 6.558, time/batch = 0.083\n",
      "1586/559050 (epoch 0), train_loss = 7.143, time/batch = 0.080\n",
      "1588/559050 (epoch 0), train_loss = 7.013, time/batch = 0.081\n",
      "1590/559050 (epoch 0), train_loss = 8.150, time/batch = 0.083\n",
      "1592/559050 (epoch 0), train_loss = 7.588, time/batch = 0.082\n",
      "1594/559050 (epoch 0), train_loss = 6.579, time/batch = 0.083\n",
      "1596/559050 (epoch 0), train_loss = 6.947, time/batch = 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598/559050 (epoch 0), train_loss = 7.941, time/batch = 0.081\n",
      "1600/559050 (epoch 0), train_loss = 8.145, time/batch = 0.080\n",
      "1602/559050 (epoch 0), train_loss = 7.345, time/batch = 0.082\n",
      "1604/559050 (epoch 0), train_loss = 5.996, time/batch = 0.081\n",
      "1606/559050 (epoch 0), train_loss = 7.966, time/batch = 0.083\n",
      "1608/559050 (epoch 0), train_loss = 8.464, time/batch = 0.080\n",
      "1610/559050 (epoch 0), train_loss = 7.199, time/batch = 0.080\n",
      "1612/559050 (epoch 0), train_loss = 7.696, time/batch = 0.082\n",
      "1614/559050 (epoch 0), train_loss = 6.680, time/batch = 0.081\n",
      "1616/559050 (epoch 0), train_loss = 5.391, time/batch = 0.081\n",
      "1618/559050 (epoch 0), train_loss = 6.856, time/batch = 0.080\n",
      "1620/559050 (epoch 0), train_loss = 5.933, time/batch = 0.082\n",
      "1622/559050 (epoch 0), train_loss = 6.872, time/batch = 0.082\n",
      "1624/559050 (epoch 0), train_loss = 6.270, time/batch = 0.082\n",
      "1626/559050 (epoch 0), train_loss = 5.013, time/batch = 0.084\n",
      "1628/559050 (epoch 0), train_loss = 8.595, time/batch = 0.081\n",
      "1630/559050 (epoch 0), train_loss = 8.727, time/batch = 0.082\n",
      "1632/559050 (epoch 0), train_loss = 6.519, time/batch = 0.083\n",
      "1634/559050 (epoch 0), train_loss = 6.568, time/batch = 0.081\n",
      "1636/559050 (epoch 0), train_loss = 5.818, time/batch = 0.083\n",
      "1638/559050 (epoch 0), train_loss = 6.622, time/batch = 0.080\n",
      "1640/559050 (epoch 0), train_loss = 5.603, time/batch = 0.081\n",
      "1642/559050 (epoch 0), train_loss = 5.967, time/batch = 0.082\n",
      "1644/559050 (epoch 0), train_loss = 9.046, time/batch = 0.082\n",
      "1646/559050 (epoch 0), train_loss = 6.533, time/batch = 0.082\n",
      "1648/559050 (epoch 0), train_loss = 5.484, time/batch = 0.082\n",
      "1650/559050 (epoch 0), train_loss = 5.232, time/batch = 0.081\n",
      "1652/559050 (epoch 0), train_loss = 6.327, time/batch = 0.082\n",
      "1654/559050 (epoch 0), train_loss = 5.928, time/batch = 0.083\n",
      "1656/559050 (epoch 0), train_loss = 6.413, time/batch = 0.081\n",
      "1658/559050 (epoch 0), train_loss = 8.093, time/batch = 0.082\n",
      "1660/559050 (epoch 0), train_loss = 5.707, time/batch = 0.082\n",
      "1662/559050 (epoch 0), train_loss = 6.590, time/batch = 0.082\n",
      "1664/559050 (epoch 0), train_loss = 7.093, time/batch = 0.084\n",
      "1666/559050 (epoch 0), train_loss = 6.423, time/batch = 0.083\n",
      "1668/559050 (epoch 0), train_loss = 8.692, time/batch = 0.082\n",
      "1670/559050 (epoch 0), train_loss = 6.744, time/batch = 0.082\n",
      "1672/559050 (epoch 0), train_loss = 6.835, time/batch = 0.083\n",
      "1674/559050 (epoch 0), train_loss = 5.644, time/batch = 0.082\n",
      "1676/559050 (epoch 0), train_loss = 6.032, time/batch = 0.083\n",
      "1678/559050 (epoch 0), train_loss = 6.923, time/batch = 0.084\n",
      "1680/559050 (epoch 0), train_loss = 6.799, time/batch = 0.082\n",
      "1682/559050 (epoch 0), train_loss = 5.725, time/batch = 0.082\n",
      "1684/559050 (epoch 0), train_loss = 6.635, time/batch = 0.082\n",
      "1686/559050 (epoch 0), train_loss = 8.259, time/batch = 0.081\n",
      "1688/559050 (epoch 0), train_loss = 5.920, time/batch = 0.082\n",
      "1690/559050 (epoch 0), train_loss = 8.202, time/batch = 0.079\n",
      "1692/559050 (epoch 0), train_loss = 6.741, time/batch = 0.079\n",
      "1694/559050 (epoch 0), train_loss = 6.710, time/batch = 0.081\n",
      "1696/559050 (epoch 0), train_loss = 6.604, time/batch = 0.082\n",
      "1698/559050 (epoch 0), train_loss = 6.407, time/batch = 0.082\n",
      "1700/559050 (epoch 0), train_loss = 7.370, time/batch = 0.082\n",
      "1702/559050 (epoch 0), train_loss = 6.743, time/batch = 0.080\n",
      "1704/559050 (epoch 0), train_loss = 6.558, time/batch = 0.082\n",
      "1706/559050 (epoch 0), train_loss = 7.404, time/batch = 0.081\n",
      "1708/559050 (epoch 0), train_loss = 6.402, time/batch = 0.081\n",
      "1710/559050 (epoch 0), train_loss = 7.536, time/batch = 0.080\n",
      "1712/559050 (epoch 0), train_loss = 7.735, time/batch = 0.082\n",
      "1714/559050 (epoch 0), train_loss = 7.005, time/batch = 0.081\n",
      "1716/559050 (epoch 0), train_loss = 6.453, time/batch = 0.089\n",
      "1718/559050 (epoch 0), train_loss = 6.348, time/batch = 0.090\n",
      "1720/559050 (epoch 0), train_loss = 7.487, time/batch = 0.091\n",
      "1722/559050 (epoch 0), train_loss = 6.396, time/batch = 0.086\n",
      "1724/559050 (epoch 0), train_loss = 6.566, time/batch = 0.091\n",
      "1726/559050 (epoch 0), train_loss = 6.704, time/batch = 0.093\n",
      "1728/559050 (epoch 0), train_loss = 8.487, time/batch = 0.092\n",
      "1730/559050 (epoch 0), train_loss = 6.124, time/batch = 0.086\n",
      "1732/559050 (epoch 0), train_loss = 7.200, time/batch = 0.086\n",
      "1734/559050 (epoch 0), train_loss = 6.901, time/batch = 0.087\n",
      "1736/559050 (epoch 0), train_loss = 6.744, time/batch = 0.088\n",
      "1738/559050 (epoch 0), train_loss = 6.820, time/batch = 0.089\n",
      "1740/559050 (epoch 0), train_loss = 5.564, time/batch = 0.086\n",
      "1742/559050 (epoch 0), train_loss = 6.384, time/batch = 0.084\n",
      "1744/559050 (epoch 0), train_loss = 6.188, time/batch = 0.084\n",
      "1746/559050 (epoch 0), train_loss = 7.611, time/batch = 0.085\n",
      "1748/559050 (epoch 0), train_loss = 7.922, time/batch = 0.090\n",
      "1750/559050 (epoch 0), train_loss = 6.163, time/batch = 0.084\n",
      "1752/559050 (epoch 0), train_loss = 5.814, time/batch = 0.080\n",
      "1754/559050 (epoch 0), train_loss = 5.593, time/batch = 0.083\n",
      "1756/559050 (epoch 0), train_loss = 7.227, time/batch = 0.080\n",
      "1758/559050 (epoch 0), train_loss = 6.580, time/batch = 0.082\n",
      "1760/559050 (epoch 0), train_loss = 6.869, time/batch = 0.078\n",
      "1762/559050 (epoch 0), train_loss = 5.908, time/batch = 0.082\n",
      "1764/559050 (epoch 0), train_loss = 6.662, time/batch = 0.080\n",
      "1766/559050 (epoch 0), train_loss = 5.355, time/batch = 0.085\n",
      "1768/559050 (epoch 0), train_loss = 7.270, time/batch = 0.081\n",
      "1770/559050 (epoch 0), train_loss = 6.557, time/batch = 0.088\n",
      "1772/559050 (epoch 0), train_loss = 6.915, time/batch = 0.087\n",
      "1774/559050 (epoch 0), train_loss = 7.741, time/batch = 0.081\n",
      "1776/559050 (epoch 0), train_loss = 6.631, time/batch = 0.082\n",
      "1778/559050 (epoch 0), train_loss = 7.611, time/batch = 0.081\n",
      "1780/559050 (epoch 0), train_loss = 6.484, time/batch = 0.082\n",
      "1782/559050 (epoch 0), train_loss = 6.379, time/batch = 0.084\n",
      "1784/559050 (epoch 0), train_loss = 6.666, time/batch = 0.081\n",
      "1786/559050 (epoch 0), train_loss = 8.753, time/batch = 0.082\n",
      "1788/559050 (epoch 0), train_loss = 7.114, time/batch = 0.082\n",
      "1790/559050 (epoch 0), train_loss = 7.183, time/batch = 0.081\n",
      "1792/559050 (epoch 0), train_loss = 6.949, time/batch = 0.082\n",
      "1794/559050 (epoch 0), train_loss = 6.799, time/batch = 0.082\n",
      "1796/559050 (epoch 0), train_loss = 7.311, time/batch = 0.081\n",
      "1798/559050 (epoch 0), train_loss = 5.298, time/batch = 0.083\n",
      "1800/559050 (epoch 0), train_loss = 5.580, time/batch = 0.080\n",
      "1802/559050 (epoch 0), train_loss = 5.622, time/batch = 0.082\n",
      "1804/559050 (epoch 0), train_loss = 6.527, time/batch = 0.082\n",
      "1806/559050 (epoch 0), train_loss = 6.090, time/batch = 0.082\n",
      "1808/559050 (epoch 0), train_loss = 6.189, time/batch = 0.081\n",
      "1810/559050 (epoch 0), train_loss = 6.557, time/batch = 0.082\n",
      "1812/559050 (epoch 0), train_loss = 5.827, time/batch = 0.081\n",
      "1814/559050 (epoch 0), train_loss = 6.615, time/batch = 0.082\n",
      "1816/559050 (epoch 0), train_loss = 6.774, time/batch = 0.082\n",
      "1818/559050 (epoch 0), train_loss = 6.800, time/batch = 0.081\n",
      "1820/559050 (epoch 0), train_loss = 6.406, time/batch = 0.082\n",
      "1822/559050 (epoch 0), train_loss = 4.779, time/batch = 0.081\n",
      "1824/559050 (epoch 0), train_loss = 5.684, time/batch = 0.080\n",
      "1826/559050 (epoch 0), train_loss = 6.294, time/batch = 0.083\n",
      "1828/559050 (epoch 0), train_loss = 6.620, time/batch = 0.081\n",
      "1830/559050 (epoch 0), train_loss = 7.183, time/batch = 0.083\n",
      "1832/559050 (epoch 0), train_loss = 6.464, time/batch = 0.082\n",
      "1834/559050 (epoch 0), train_loss = 6.367, time/batch = 0.082\n",
      "1836/559050 (epoch 0), train_loss = 6.261, time/batch = 0.081\n",
      "1838/559050 (epoch 0), train_loss = 5.867, time/batch = 0.081\n",
      "1840/559050 (epoch 0), train_loss = 6.552, time/batch = 0.081\n",
      "1842/559050 (epoch 0), train_loss = 5.479, time/batch = 0.082\n",
      "1844/559050 (epoch 0), train_loss = 7.361, time/batch = 0.081\n",
      "1846/559050 (epoch 0), train_loss = 7.419, time/batch = 0.082\n",
      "1848/559050 (epoch 0), train_loss = 6.547, time/batch = 0.082\n",
      "1850/559050 (epoch 0), train_loss = 6.930, time/batch = 0.082\n",
      "1852/559050 (epoch 0), train_loss = 5.794, time/batch = 0.082\n",
      "1854/559050 (epoch 0), train_loss = 5.433, time/batch = 0.084\n",
      "1856/559050 (epoch 0), train_loss = 5.556, time/batch = 0.080\n",
      "1858/559050 (epoch 0), train_loss = 7.842, time/batch = 0.080\n",
      "1860/559050 (epoch 0), train_loss = 6.644, time/batch = 0.080\n",
      "1862/559050 (epoch 0), train_loss = 6.704, time/batch = 0.080\n",
      "1864/559050 (epoch 0), train_loss = 7.310, time/batch = 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866/559050 (epoch 0), train_loss = 6.963, time/batch = 0.083\n",
      "1868/559050 (epoch 0), train_loss = 6.590, time/batch = 0.082\n",
      "1870/559050 (epoch 0), train_loss = 5.342, time/batch = 0.082\n",
      "1872/559050 (epoch 0), train_loss = 6.441, time/batch = 0.081\n",
      "1874/559050 (epoch 0), train_loss = 7.824, time/batch = 0.080\n",
      "1876/559050 (epoch 0), train_loss = 5.044, time/batch = 0.079\n",
      "1878/559050 (epoch 0), train_loss = 5.841, time/batch = 0.081\n",
      "1880/559050 (epoch 0), train_loss = 5.731, time/batch = 0.083\n",
      "1882/559050 (epoch 0), train_loss = 7.119, time/batch = 0.081\n",
      "1884/559050 (epoch 0), train_loss = 6.660, time/batch = 0.083\n",
      "1886/559050 (epoch 0), train_loss = 6.526, time/batch = 0.083\n",
      "1888/559050 (epoch 0), train_loss = 6.291, time/batch = 0.079\n",
      "1890/559050 (epoch 0), train_loss = 7.522, time/batch = 0.080\n",
      "1892/559050 (epoch 0), train_loss = 5.856, time/batch = 0.081\n",
      "1894/559050 (epoch 0), train_loss = 6.559, time/batch = 0.081\n",
      "1896/559050 (epoch 0), train_loss = 4.902, time/batch = 0.081\n",
      "1898/559050 (epoch 0), train_loss = 5.283, time/batch = 0.081\n",
      "1900/559050 (epoch 0), train_loss = 6.501, time/batch = 0.081\n",
      "1902/559050 (epoch 0), train_loss = 6.425, time/batch = 0.083\n",
      "1904/559050 (epoch 0), train_loss = 6.988, time/batch = 0.082\n",
      "1906/559050 (epoch 0), train_loss = 6.044, time/batch = 0.082\n",
      "1908/559050 (epoch 0), train_loss = 6.476, time/batch = 0.080\n",
      "1910/559050 (epoch 0), train_loss = 5.133, time/batch = 0.081\n",
      "1912/559050 (epoch 0), train_loss = 5.722, time/batch = 0.085\n",
      "1914/559050 (epoch 0), train_loss = 7.135, time/batch = 0.082\n",
      "1916/559050 (epoch 0), train_loss = 6.850, time/batch = 0.082\n",
      "1918/559050 (epoch 0), train_loss = 7.456, time/batch = 0.081\n",
      "1920/559050 (epoch 0), train_loss = 6.019, time/batch = 0.079\n",
      "1922/559050 (epoch 0), train_loss = 6.947, time/batch = 0.082\n",
      "1924/559050 (epoch 0), train_loss = 7.564, time/batch = 0.082\n",
      "1926/559050 (epoch 0), train_loss = 5.038, time/batch = 0.082\n",
      "1928/559050 (epoch 0), train_loss = 5.915, time/batch = 0.081\n",
      "1930/559050 (epoch 0), train_loss = 7.138, time/batch = 0.082\n",
      "1932/559050 (epoch 0), train_loss = 5.969, time/batch = 0.081\n",
      "1934/559050 (epoch 0), train_loss = 7.538, time/batch = 0.082\n",
      "1936/559050 (epoch 0), train_loss = 7.384, time/batch = 0.082\n",
      "1938/559050 (epoch 0), train_loss = 7.186, time/batch = 0.081\n",
      "1940/559050 (epoch 0), train_loss = 5.535, time/batch = 0.081\n",
      "1942/559050 (epoch 0), train_loss = 6.709, time/batch = 0.079\n",
      "1944/559050 (epoch 0), train_loss = 6.430, time/batch = 0.081\n",
      "1946/559050 (epoch 0), train_loss = 7.449, time/batch = 0.080\n",
      "1948/559050 (epoch 0), train_loss = 6.464, time/batch = 0.080\n",
      "1950/559050 (epoch 0), train_loss = 7.817, time/batch = 0.081\n",
      "1952/559050 (epoch 0), train_loss = 6.844, time/batch = 0.079\n",
      "1954/559050 (epoch 0), train_loss = 6.333, time/batch = 0.081\n",
      "1956/559050 (epoch 0), train_loss = 7.368, time/batch = 0.082\n",
      "1958/559050 (epoch 0), train_loss = 5.756, time/batch = 0.082\n",
      "1960/559050 (epoch 0), train_loss = 6.359, time/batch = 0.082\n",
      "1962/559050 (epoch 0), train_loss = 7.148, time/batch = 0.082\n",
      "1964/559050 (epoch 0), train_loss = 6.048, time/batch = 0.082\n",
      "1966/559050 (epoch 0), train_loss = 6.044, time/batch = 0.083\n",
      "1968/559050 (epoch 0), train_loss = 5.699, time/batch = 0.081\n",
      "1970/559050 (epoch 0), train_loss = 6.626, time/batch = 0.082\n",
      "1972/559050 (epoch 0), train_loss = 5.140, time/batch = 0.082\n",
      "1974/559050 (epoch 0), train_loss = 6.765, time/batch = 0.081\n",
      "1976/559050 (epoch 0), train_loss = 7.840, time/batch = 0.081\n",
      "1978/559050 (epoch 0), train_loss = 7.600, time/batch = 0.083\n",
      "1980/559050 (epoch 0), train_loss = 8.000, time/batch = 0.082\n",
      "1982/559050 (epoch 0), train_loss = 6.407, time/batch = 0.081\n",
      "1984/559050 (epoch 0), train_loss = 6.485, time/batch = 0.080\n",
      "1986/559050 (epoch 0), train_loss = 6.718, time/batch = 0.082\n",
      "1988/559050 (epoch 0), train_loss = 5.104, time/batch = 0.082\n",
      "1990/559050 (epoch 0), train_loss = 7.213, time/batch = 0.079\n",
      "1992/559050 (epoch 0), train_loss = 7.772, time/batch = 0.081\n",
      "1994/559050 (epoch 0), train_loss = 6.754, time/batch = 0.082\n",
      "1996/559050 (epoch 0), train_loss = 7.505, time/batch = 0.082\n",
      "1998/559050 (epoch 0), train_loss = 6.736, time/batch = 0.081\n",
      "2000/559050 (epoch 0), train_loss = 7.825, time/batch = 0.082\n",
      "2002/559050 (epoch 0), train_loss = 5.636, time/batch = 0.081\n",
      "2004/559050 (epoch 0), train_loss = 6.524, time/batch = 0.082\n",
      "2006/559050 (epoch 0), train_loss = 7.105, time/batch = 0.081\n",
      "2008/559050 (epoch 0), train_loss = 5.440, time/batch = 0.080\n",
      "2010/559050 (epoch 0), train_loss = 7.349, time/batch = 0.082\n",
      "2012/559050 (epoch 0), train_loss = 6.240, time/batch = 0.082\n",
      "2014/559050 (epoch 0), train_loss = 6.899, time/batch = 0.081\n",
      "2016/559050 (epoch 0), train_loss = 6.845, time/batch = 0.083\n",
      "2018/559050 (epoch 0), train_loss = 7.204, time/batch = 0.081\n",
      "2020/559050 (epoch 0), train_loss = 7.680, time/batch = 0.082\n",
      "2022/559050 (epoch 0), train_loss = 8.217, time/batch = 0.081\n",
      "2024/559050 (epoch 0), train_loss = 7.270, time/batch = 0.081\n",
      "2026/559050 (epoch 0), train_loss = 7.546, time/batch = 0.082\n",
      "2028/559050 (epoch 0), train_loss = 7.956, time/batch = 0.082\n",
      "2030/559050 (epoch 0), train_loss = 7.003, time/batch = 0.080\n",
      "2032/559050 (epoch 0), train_loss = 6.888, time/batch = 0.082\n",
      "2034/559050 (epoch 0), train_loss = 6.653, time/batch = 0.080\n",
      "2036/559050 (epoch 0), train_loss = 7.584, time/batch = 0.082\n",
      "2038/559050 (epoch 0), train_loss = 6.905, time/batch = 0.083\n",
      "2040/559050 (epoch 0), train_loss = 6.751, time/batch = 0.081\n",
      "2042/559050 (epoch 0), train_loss = 7.168, time/batch = 0.081\n",
      "2044/559050 (epoch 0), train_loss = 6.299, time/batch = 0.081\n",
      "2046/559050 (epoch 0), train_loss = 6.400, time/batch = 0.081\n",
      "2048/559050 (epoch 0), train_loss = 5.315, time/batch = 0.080\n",
      "2050/559050 (epoch 0), train_loss = 7.924, time/batch = 0.081\n",
      "2052/559050 (epoch 0), train_loss = 6.008, time/batch = 0.082\n",
      "2054/559050 (epoch 0), train_loss = 7.010, time/batch = 0.081\n",
      "2056/559050 (epoch 0), train_loss = 6.928, time/batch = 0.081\n",
      "2058/559050 (epoch 0), train_loss = 6.217, time/batch = 0.082\n",
      "2060/559050 (epoch 0), train_loss = 6.327, time/batch = 0.082\n",
      "2062/559050 (epoch 0), train_loss = 5.858, time/batch = 0.082\n",
      "2064/559050 (epoch 0), train_loss = 5.284, time/batch = 0.080\n",
      "2066/559050 (epoch 0), train_loss = 5.855, time/batch = 0.080\n",
      "2068/559050 (epoch 0), train_loss = 7.052, time/batch = 0.081\n",
      "2070/559050 (epoch 0), train_loss = 7.637, time/batch = 0.080\n",
      "2072/559050 (epoch 0), train_loss = 5.765, time/batch = 0.080\n",
      "2074/559050 (epoch 0), train_loss = 7.480, time/batch = 0.081\n",
      "2076/559050 (epoch 0), train_loss = 6.835, time/batch = 0.080\n",
      "2078/559050 (epoch 0), train_loss = 4.955, time/batch = 0.079\n",
      "2080/559050 (epoch 0), train_loss = 5.884, time/batch = 0.081\n",
      "2082/559050 (epoch 0), train_loss = 6.408, time/batch = 0.082\n",
      "2084/559050 (epoch 0), train_loss = 6.516, time/batch = 0.080\n",
      "2086/559050 (epoch 0), train_loss = 6.390, time/batch = 0.083\n",
      "2088/559050 (epoch 0), train_loss = 7.232, time/batch = 0.081\n",
      "2090/559050 (epoch 0), train_loss = 6.597, time/batch = 0.082\n",
      "2092/559050 (epoch 0), train_loss = 6.550, time/batch = 0.080\n",
      "2094/559050 (epoch 0), train_loss = 8.283, time/batch = 0.084\n",
      "2096/559050 (epoch 0), train_loss = 5.570, time/batch = 0.080\n",
      "2098/559050 (epoch 0), train_loss = 6.223, time/batch = 0.081\n",
      "2100/559050 (epoch 0), train_loss = 6.724, time/batch = 0.081\n",
      "2102/559050 (epoch 0), train_loss = 6.041, time/batch = 0.082\n",
      "2104/559050 (epoch 0), train_loss = 6.825, time/batch = 0.081\n",
      "2106/559050 (epoch 0), train_loss = 7.266, time/batch = 0.081\n",
      "2108/559050 (epoch 0), train_loss = 6.255, time/batch = 0.082\n",
      "2110/559050 (epoch 0), train_loss = 5.990, time/batch = 0.081\n",
      "2112/559050 (epoch 0), train_loss = 6.518, time/batch = 0.080\n",
      "2114/559050 (epoch 0), train_loss = 7.647, time/batch = 0.080\n",
      "2116/559050 (epoch 0), train_loss = 7.722, time/batch = 0.081\n",
      "2118/559050 (epoch 0), train_loss = 6.554, time/batch = 0.083\n",
      "2120/559050 (epoch 0), train_loss = 7.549, time/batch = 0.082\n",
      "2122/559050 (epoch 0), train_loss = 6.913, time/batch = 0.081\n",
      "2124/559050 (epoch 0), train_loss = 8.884, time/batch = 0.081\n",
      "2126/559050 (epoch 0), train_loss = 6.601, time/batch = 0.081\n",
      "2128/559050 (epoch 0), train_loss = 5.809, time/batch = 0.081\n",
      "2130/559050 (epoch 0), train_loss = 8.321, time/batch = 0.082\n",
      "2132/559050 (epoch 0), train_loss = 6.958, time/batch = 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134/559050 (epoch 0), train_loss = 6.345, time/batch = 0.082\n",
      "2136/559050 (epoch 0), train_loss = 5.977, time/batch = 0.079\n",
      "2138/559050 (epoch 0), train_loss = 6.419, time/batch = 0.081\n",
      "2140/559050 (epoch 0), train_loss = 5.382, time/batch = 0.082\n",
      "2142/559050 (epoch 0), train_loss = 6.424, time/batch = 0.081\n",
      "2144/559050 (epoch 0), train_loss = 6.188, time/batch = 0.079\n",
      "2146/559050 (epoch 0), train_loss = 7.251, time/batch = 0.081\n",
      "2148/559050 (epoch 0), train_loss = 5.914, time/batch = 0.080\n",
      "2150/559050 (epoch 0), train_loss = 6.243, time/batch = 0.082\n",
      "2152/559050 (epoch 0), train_loss = 7.039, time/batch = 0.080\n",
      "2154/559050 (epoch 0), train_loss = 7.156, time/batch = 0.081\n",
      "2156/559050 (epoch 0), train_loss = 5.934, time/batch = 0.081\n",
      "2158/559050 (epoch 0), train_loss = 6.014, time/batch = 0.082\n",
      "2160/559050 (epoch 0), train_loss = 5.980, time/batch = 0.081\n",
      "2162/559050 (epoch 0), train_loss = 8.722, time/batch = 0.079\n",
      "2164/559050 (epoch 0), train_loss = 4.951, time/batch = 0.080\n",
      "2166/559050 (epoch 0), train_loss = 6.490, time/batch = 0.080\n",
      "2168/559050 (epoch 0), train_loss = 7.299, time/batch = 0.082\n",
      "2170/559050 (epoch 0), train_loss = 7.417, time/batch = 0.082\n",
      "2172/559050 (epoch 0), train_loss = 5.876, time/batch = 0.081\n",
      "2174/559050 (epoch 0), train_loss = 6.347, time/batch = 0.081\n",
      "2176/559050 (epoch 0), train_loss = 6.302, time/batch = 0.081\n",
      "2178/559050 (epoch 0), train_loss = 6.528, time/batch = 0.080\n",
      "2180/559050 (epoch 0), train_loss = 7.107, time/batch = 0.081\n",
      "2182/559050 (epoch 0), train_loss = 7.143, time/batch = 0.082\n",
      "2184/559050 (epoch 0), train_loss = 5.559, time/batch = 0.081\n",
      "2186/559050 (epoch 0), train_loss = 7.167, time/batch = 0.080\n",
      "2188/559050 (epoch 0), train_loss = 6.775, time/batch = 0.080\n",
      "2190/559050 (epoch 0), train_loss = 6.165, time/batch = 0.079\n",
      "2192/559050 (epoch 0), train_loss = 6.518, time/batch = 0.082\n",
      "2194/559050 (epoch 0), train_loss = 5.781, time/batch = 0.081\n",
      "2196/559050 (epoch 0), train_loss = 5.857, time/batch = 0.082\n",
      "2198/559050 (epoch 0), train_loss = 6.447, time/batch = 0.082\n",
      "2200/559050 (epoch 0), train_loss = 6.545, time/batch = 0.081\n",
      "2202/559050 (epoch 0), train_loss = 6.032, time/batch = 0.081\n",
      "2204/559050 (epoch 0), train_loss = 5.486, time/batch = 0.082\n",
      "2206/559050 (epoch 0), train_loss = 6.754, time/batch = 0.081\n",
      "2208/559050 (epoch 0), train_loss = 7.659, time/batch = 0.080\n",
      "2210/559050 (epoch 0), train_loss = 6.435, time/batch = 0.082\n",
      "2212/559050 (epoch 0), train_loss = 5.729, time/batch = 0.080\n",
      "2214/559050 (epoch 0), train_loss = 6.717, time/batch = 0.081\n",
      "2216/559050 (epoch 0), train_loss = 7.043, time/batch = 0.081\n",
      "2218/559050 (epoch 0), train_loss = 6.275, time/batch = 0.080\n",
      "2220/559050 (epoch 0), train_loss = 6.933, time/batch = 0.081\n",
      "2222/559050 (epoch 0), train_loss = 5.845, time/batch = 0.082\n",
      "2224/559050 (epoch 0), train_loss = 6.102, time/batch = 0.081\n",
      "2226/559050 (epoch 0), train_loss = 6.336, time/batch = 0.081\n",
      "2228/559050 (epoch 0), train_loss = 6.258, time/batch = 0.081\n",
      "2230/559050 (epoch 0), train_loss = 7.338, time/batch = 0.082\n",
      "2232/559050 (epoch 0), train_loss = 6.302, time/batch = 0.078\n",
      "2234/559050 (epoch 0), train_loss = 6.990, time/batch = 0.083\n",
      "2236/559050 (epoch 0), train_loss = 6.184, time/batch = 0.082\n",
      "2238/559050 (epoch 0), train_loss = 7.393, time/batch = 0.081\n",
      "2240/559050 (epoch 0), train_loss = 6.966, time/batch = 0.081\n",
      "2242/559050 (epoch 0), train_loss = 6.923, time/batch = 0.081\n",
      "2244/559050 (epoch 0), train_loss = 5.483, time/batch = 0.081\n",
      "2246/559050 (epoch 0), train_loss = 7.228, time/batch = 0.083\n",
      "2248/559050 (epoch 0), train_loss = 5.700, time/batch = 0.081\n",
      "2250/559050 (epoch 0), train_loss = 6.289, time/batch = 0.081\n",
      "2252/559050 (epoch 0), train_loss = 6.532, time/batch = 0.082\n",
      "2254/559050 (epoch 0), train_loss = 6.926, time/batch = 0.081\n",
      "2256/559050 (epoch 0), train_loss = 7.918, time/batch = 0.081\n",
      "2258/559050 (epoch 0), train_loss = 6.210, time/batch = 0.082\n",
      "2260/559050 (epoch 0), train_loss = 6.345, time/batch = 0.081\n",
      "2262/559050 (epoch 0), train_loss = 6.562, time/batch = 0.081\n",
      "2264/559050 (epoch 0), train_loss = 6.638, time/batch = 0.081\n",
      "2266/559050 (epoch 0), train_loss = 6.492, time/batch = 0.081\n",
      "2268/559050 (epoch 0), train_loss = 6.488, time/batch = 0.083\n",
      "2270/559050 (epoch 0), train_loss = 7.829, time/batch = 0.082\n",
      "2272/559050 (epoch 0), train_loss = 6.661, time/batch = 0.081\n",
      "2274/559050 (epoch 0), train_loss = 6.638, time/batch = 0.082\n",
      "2276/559050 (epoch 0), train_loss = 6.250, time/batch = 0.080\n",
      "2278/559050 (epoch 0), train_loss = 6.310, time/batch = 0.081\n",
      "2280/559050 (epoch 0), train_loss = 7.467, time/batch = 0.080\n",
      "2282/559050 (epoch 0), train_loss = 8.056, time/batch = 0.082\n",
      "2284/559050 (epoch 0), train_loss = 8.104, time/batch = 0.080\n",
      "2286/559050 (epoch 0), train_loss = 5.945, time/batch = 0.083\n",
      "2288/559050 (epoch 0), train_loss = 5.347, time/batch = 0.079\n",
      "2290/559050 (epoch 0), train_loss = 5.729, time/batch = 0.080\n",
      "2292/559050 (epoch 0), train_loss = 6.364, time/batch = 0.081\n",
      "2294/559050 (epoch 0), train_loss = 7.021, time/batch = 0.082\n",
      "2296/559050 (epoch 0), train_loss = 6.426, time/batch = 0.081\n",
      "2298/559050 (epoch 0), train_loss = 6.246, time/batch = 0.081\n",
      "2300/559050 (epoch 0), train_loss = 8.653, time/batch = 0.080\n",
      "2302/559050 (epoch 0), train_loss = 6.315, time/batch = 0.081\n",
      "2304/559050 (epoch 0), train_loss = 8.232, time/batch = 0.081\n",
      "2306/559050 (epoch 0), train_loss = 6.964, time/batch = 0.082\n",
      "2308/559050 (epoch 0), train_loss = 8.211, time/batch = 0.080\n",
      "2310/559050 (epoch 0), train_loss = 7.602, time/batch = 0.081\n",
      "2312/559050 (epoch 0), train_loss = 7.466, time/batch = 0.080\n",
      "2314/559050 (epoch 0), train_loss = 5.690, time/batch = 0.081\n",
      "2316/559050 (epoch 0), train_loss = 6.188, time/batch = 0.083\n",
      "2318/559050 (epoch 0), train_loss = 6.413, time/batch = 0.082\n",
      "2320/559050 (epoch 0), train_loss = 6.090, time/batch = 0.082\n",
      "2322/559050 (epoch 0), train_loss = 7.615, time/batch = 0.084\n",
      "2324/559050 (epoch 0), train_loss = 5.769, time/batch = 0.080\n",
      "2326/559050 (epoch 0), train_loss = 7.488, time/batch = 0.081\n",
      "2328/559050 (epoch 0), train_loss = 6.925, time/batch = 0.082\n",
      "2330/559050 (epoch 0), train_loss = 6.461, time/batch = 0.081\n",
      "2332/559050 (epoch 0), train_loss = 6.090, time/batch = 0.081\n",
      "2334/559050 (epoch 0), train_loss = 5.128, time/batch = 0.080\n",
      "2336/559050 (epoch 0), train_loss = 6.182, time/batch = 0.079\n",
      "2338/559050 (epoch 0), train_loss = 8.585, time/batch = 0.081\n",
      "2340/559050 (epoch 0), train_loss = 7.637, time/batch = 0.081\n",
      "2342/559050 (epoch 0), train_loss = 7.072, time/batch = 0.081\n",
      "2344/559050 (epoch 0), train_loss = 6.563, time/batch = 0.081\n",
      "2346/559050 (epoch 0), train_loss = 6.876, time/batch = 0.081\n",
      "2348/559050 (epoch 0), train_loss = 6.071, time/batch = 0.081\n",
      "2350/559050 (epoch 0), train_loss = 6.644, time/batch = 0.081\n",
      "2352/559050 (epoch 0), train_loss = 7.732, time/batch = 0.079\n",
      "2354/559050 (epoch 0), train_loss = 8.102, time/batch = 0.083\n",
      "2356/559050 (epoch 0), train_loss = 5.924, time/batch = 0.080\n",
      "2358/559050 (epoch 0), train_loss = 6.863, time/batch = 0.081\n",
      "2360/559050 (epoch 0), train_loss = 5.766, time/batch = 0.081\n",
      "2362/559050 (epoch 0), train_loss = 6.756, time/batch = 0.081\n",
      "2364/559050 (epoch 0), train_loss = 6.058, time/batch = 0.081\n",
      "2366/559050 (epoch 0), train_loss = 6.156, time/batch = 0.081\n",
      "2368/559050 (epoch 0), train_loss = 5.266, time/batch = 0.082\n",
      "2370/559050 (epoch 0), train_loss = 6.546, time/batch = 0.081\n",
      "2372/559050 (epoch 0), train_loss = 6.560, time/batch = 0.081\n",
      "2374/559050 (epoch 0), train_loss = 5.599, time/batch = 0.082\n",
      "2376/559050 (epoch 0), train_loss = 6.220, time/batch = 0.081\n",
      "2378/559050 (epoch 0), train_loss = 6.782, time/batch = 0.083\n",
      "2380/559050 (epoch 0), train_loss = 5.711, time/batch = 0.082\n",
      "2382/559050 (epoch 0), train_loss = 5.940, time/batch = 0.081\n",
      "2384/559050 (epoch 0), train_loss = 6.049, time/batch = 0.081\n",
      "2386/559050 (epoch 0), train_loss = 5.783, time/batch = 0.084\n",
      "2388/559050 (epoch 0), train_loss = 6.926, time/batch = 0.081\n",
      "2390/559050 (epoch 0), train_loss = 5.778, time/batch = 0.082\n",
      "2392/559050 (epoch 0), train_loss = 6.377, time/batch = 0.082\n",
      "2394/559050 (epoch 0), train_loss = 6.236, time/batch = 0.081\n",
      "2396/559050 (epoch 0), train_loss = 5.924, time/batch = 0.081\n",
      "2398/559050 (epoch 0), train_loss = 6.550, time/batch = 0.081\n",
      "2400/559050 (epoch 0), train_loss = 6.305, time/batch = 0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2402/559050 (epoch 0), train_loss = 6.726, time/batch = 0.079\n",
      "2404/559050 (epoch 0), train_loss = 6.442, time/batch = 0.083\n",
      "2406/559050 (epoch 0), train_loss = 5.348, time/batch = 0.081\n",
      "2408/559050 (epoch 0), train_loss = 6.671, time/batch = 0.082\n",
      "2410/559050 (epoch 0), train_loss = 5.742, time/batch = 0.083\n",
      "2412/559050 (epoch 0), train_loss = 7.169, time/batch = 0.080\n",
      "2414/559050 (epoch 0), train_loss = 6.419, time/batch = 0.082\n",
      "2416/559050 (epoch 0), train_loss = 6.344, time/batch = 0.081\n",
      "2418/559050 (epoch 0), train_loss = 6.356, time/batch = 0.081\n",
      "2420/559050 (epoch 0), train_loss = 7.709, time/batch = 0.082\n",
      "2422/559050 (epoch 0), train_loss = 7.112, time/batch = 0.080\n",
      "2424/559050 (epoch 0), train_loss = 5.722, time/batch = 0.081\n",
      "2426/559050 (epoch 0), train_loss = 7.112, time/batch = 0.083\n",
      "2428/559050 (epoch 0), train_loss = 5.429, time/batch = 0.083\n",
      "2430/559050 (epoch 0), train_loss = 6.990, time/batch = 0.084\n",
      "2432/559050 (epoch 0), train_loss = 6.582, time/batch = 0.082\n",
      "2434/559050 (epoch 0), train_loss = 6.089, time/batch = 0.080\n",
      "2436/559050 (epoch 0), train_loss = 6.140, time/batch = 0.081\n",
      "2438/559050 (epoch 0), train_loss = 5.560, time/batch = 0.081\n",
      "2440/559050 (epoch 0), train_loss = 6.028, time/batch = 0.081\n",
      "2442/559050 (epoch 0), train_loss = 6.349, time/batch = 0.079\n",
      "2444/559050 (epoch 0), train_loss = 7.118, time/batch = 0.080\n",
      "2446/559050 (epoch 0), train_loss = 7.634, time/batch = 0.081\n",
      "2448/559050 (epoch 0), train_loss = 6.487, time/batch = 0.079\n",
      "2450/559050 (epoch 0), train_loss = 6.298, time/batch = 0.080\n",
      "2452/559050 (epoch 0), train_loss = 5.527, time/batch = 0.082\n",
      "2454/559050 (epoch 0), train_loss = 6.728, time/batch = 0.081\n",
      "2456/559050 (epoch 0), train_loss = 5.873, time/batch = 0.081\n",
      "2458/559050 (epoch 0), train_loss = 5.662, time/batch = 0.079\n",
      "2460/559050 (epoch 0), train_loss = 6.454, time/batch = 0.079\n",
      "2462/559050 (epoch 0), train_loss = 5.362, time/batch = 0.081\n",
      "2464/559050 (epoch 0), train_loss = 6.024, time/batch = 0.080\n",
      "2466/559050 (epoch 0), train_loss = 5.920, time/batch = 0.080\n",
      "2468/559050 (epoch 0), train_loss = 6.807, time/batch = 0.078\n",
      "2470/559050 (epoch 0), train_loss = 5.952, time/batch = 0.080\n",
      "2472/559050 (epoch 0), train_loss = 5.896, time/batch = 0.083\n",
      "2474/559050 (epoch 0), train_loss = 6.849, time/batch = 0.081\n",
      "2476/559050 (epoch 0), train_loss = 5.058, time/batch = 0.081\n",
      "2478/559050 (epoch 0), train_loss = 5.594, time/batch = 0.081\n",
      "2480/559050 (epoch 0), train_loss = 5.875, time/batch = 0.079\n",
      "2482/559050 (epoch 0), train_loss = 5.180, time/batch = 0.082\n",
      "2484/559050 (epoch 0), train_loss = 6.425, time/batch = 0.079\n",
      "2486/559050 (epoch 0), train_loss = 5.686, time/batch = 0.080\n",
      "2488/559050 (epoch 0), train_loss = 5.749, time/batch = 0.082\n",
      "2490/559050 (epoch 0), train_loss = 4.433, time/batch = 0.080\n",
      "2492/559050 (epoch 0), train_loss = 6.621, time/batch = 0.079\n",
      "2494/559050 (epoch 0), train_loss = 6.640, time/batch = 0.085\n",
      "2496/559050 (epoch 0), train_loss = 6.214, time/batch = 0.080\n",
      "2498/559050 (epoch 0), train_loss = 7.377, time/batch = 0.081\n",
      "2500/559050 (epoch 0), train_loss = 5.990, time/batch = 0.081\n",
      "2502/559050 (epoch 0), train_loss = 6.156, time/batch = 0.081\n",
      "2504/559050 (epoch 0), train_loss = 5.302, time/batch = 0.083\n",
      "2506/559050 (epoch 0), train_loss = 5.712, time/batch = 0.081\n",
      "2508/559050 (epoch 0), train_loss = 5.780, time/batch = 0.080\n",
      "2510/559050 (epoch 0), train_loss = 6.406, time/batch = 0.081\n",
      "2512/559050 (epoch 0), train_loss = 6.274, time/batch = 0.080\n",
      "2514/559050 (epoch 0), train_loss = 8.250, time/batch = 0.082\n",
      "2516/559050 (epoch 0), train_loss = 7.244, time/batch = 0.081\n",
      "2518/559050 (epoch 0), train_loss = 5.956, time/batch = 0.082\n",
      "2520/559050 (epoch 0), train_loss = 5.333, time/batch = 0.081\n",
      "2522/559050 (epoch 0), train_loss = 5.634, time/batch = 0.082\n",
      "2524/559050 (epoch 0), train_loss = 8.343, time/batch = 0.079\n",
      "2526/559050 (epoch 0), train_loss = 6.311, time/batch = 0.078\n",
      "2528/559050 (epoch 0), train_loss = 6.103, time/batch = 0.080\n",
      "2530/559050 (epoch 0), train_loss = 5.414, time/batch = 0.081\n",
      "2532/559050 (epoch 0), train_loss = 6.345, time/batch = 0.082\n",
      "2534/559050 (epoch 0), train_loss = 6.823, time/batch = 0.081\n",
      "2536/559050 (epoch 0), train_loss = 5.770, time/batch = 0.081\n",
      "2538/559050 (epoch 0), train_loss = 5.914, time/batch = 0.082\n",
      "2540/559050 (epoch 0), train_loss = 6.809, time/batch = 0.079\n",
      "2542/559050 (epoch 0), train_loss = 6.318, time/batch = 0.082\n",
      "2544/559050 (epoch 0), train_loss = 5.250, time/batch = 0.079\n",
      "2546/559050 (epoch 0), train_loss = 7.827, time/batch = 0.082\n",
      "2548/559050 (epoch 0), train_loss = 6.990, time/batch = 0.081\n",
      "2550/559050 (epoch 0), train_loss = 5.652, time/batch = 0.080\n",
      "2552/559050 (epoch 0), train_loss = 6.835, time/batch = 0.082\n",
      "2554/559050 (epoch 0), train_loss = 6.076, time/batch = 0.080\n",
      "2556/559050 (epoch 0), train_loss = 5.885, time/batch = 0.081\n",
      "2558/559050 (epoch 0), train_loss = 6.637, time/batch = 0.080\n",
      "2560/559050 (epoch 0), train_loss = 6.831, time/batch = 0.080\n",
      "2562/559050 (epoch 0), train_loss = 6.209, time/batch = 0.079\n",
      "2564/559050 (epoch 0), train_loss = 6.708, time/batch = 0.080\n",
      "2566/559050 (epoch 0), train_loss = 6.023, time/batch = 0.081\n",
      "2568/559050 (epoch 0), train_loss = 6.069, time/batch = 0.079\n",
      "2570/559050 (epoch 0), train_loss = 5.876, time/batch = 0.081\n",
      "2572/559050 (epoch 0), train_loss = 8.317, time/batch = 0.081\n"
     ]
    }
   ],
   "source": [
    "data_dir= \"/home/vibertron/Desktop\"\n",
    "rnn_size = 256 \n",
    "num_layers = 2 \n",
    "model = 'lstm' \n",
    "batch_size = 2 \n",
    "seq_length = 5 \n",
    "num_epochs = 50\n",
    "save_every = 100000\n",
    "grad_clip = 5. \n",
    "learning_rate= 0.002 \n",
    "decay_rate = 0.97 \n",
    "gpu_mem = 0.666 \n",
    "init_from = None\n",
    "\n",
    "input_file = os.path.join(data_dir, \"corpx.txt\")\n",
    "vocab_file = os.path.join(data_dir, \"vocab1.pkl\")\n",
    "\n",
    "with codecs.open(input_file, \"r\", encoding=None) as f:\n",
    "    data = f.read()\n",
    "data = data.replace(\",\",\" \")\n",
    "data = data.replace(\".\",\" \")\n",
    "data = data.replace(\"''\",\" \")\n",
    "x_text = data.split()\n",
    "\n",
    "word_counts = collections.Counter(x_text)\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "vocab_size = len(words)\n",
    "with open(vocab_file, 'wb') as f:\n",
    "    cPickle.dump((words), f)\n",
    "\n",
    "    tensor = np.array(list(map(vocab.get, x_text)))\n",
    "np.save(\"C:\\\\Users\\\\SAIKUMAR\\\\Desktop\\\\vikram vqa\\\\__MACOSX\\\\caption_sneak\\\\data\\\\tensorfile.npy\",tensor)\n",
    "\n",
    "print('tensor is:' + str(tensor))\n",
    "print(\"It's shape: \" + str(np.shape(tensor)))\n",
    "\n",
    "num_batches = int((tensor.size) / (batch_size * seq_length))\n",
    "print('number of batches is: ' + str(num_batches))\n",
    "\n",
    "tensor = tensor[:num_batches * batch_size * seq_length]\n",
    "print('The shape of the new tensor is: '+ str(np.shape(tensor)))\n",
    "xdata = tensor\n",
    "ydata = np.copy(tensor)\n",
    "\n",
    "ydata[:-1] = xdata[1:]\n",
    "print(xdata,\" and \",ydata)\n",
    "ydata[-1] = xdata[0]\n",
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\n",
    "y_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n",
    "\n",
    "pointer = 0\n",
    "#with open(os.path.join(save_dir, 'words_vocab.pkl'), 'wb') as f:\n",
    "    #cPickle.dump((words, vocab), f)\n",
    "\n",
    "model = Model(data_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size)\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "        for e in range(model.epoch_pointer.eval(), num_epochs):\n",
    "            sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "            \n",
    "            state = sess.run(model.initial_state)\n",
    "            speed = 0\n",
    "            pointer = 0\n",
    "            \n",
    "            if init_from is None:\n",
    "                assign_op = model.epoch_pointer.assign(e)\n",
    "                sess.run(assign_op)\n",
    "\n",
    "            if init_from is not None:\n",
    "                pointer = model.batch_pointer.eval()\n",
    "                init_from = None\n",
    "\n",
    "            for b in range(pointer, num_batches):\n",
    "                start = time.time()\n",
    "                x, y = x_batches[pointer], y_batches[pointer]\n",
    "                pointer += 1\n",
    "                feed = {model.input_data: x, model.targets: y, model.initial_state: state,\n",
    "                        model.batch_time: speed}\n",
    "                summary, train_loss, state, _, _ = sess.run([merged, model.cost, model.final_state,\n",
    "                                                             model.train_op, model.inc_batch_pointer_op], feed)\n",
    "            \n",
    "                speed = time.time() - start\n",
    "\n",
    "                if (e * num_batches + b) % batch_size == 0:\n",
    "                    print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                        .format(e * num_batches + b,\n",
    "                                num_epochs * num_batches,\n",
    "                                e, train_loss, speed))\n",
    "                \n",
    "                if (e * num_batches + b) % save_every == 0 \\\n",
    "                        or (e==num_epochs-1 and b == num_batches-1): # save for the last result\n",
    "                    checkpoint_path = os.path.join(\"C:\\\\Users\\SAIKUMAR\\\\Desktop\\\\vikram vqa\\\\__MACOSX\\\\caption_sneak\\\\data\", \"model_test.ckpt\")\n",
    "                    saver.save(sess, checkpoint_path, global_step = e * num_batches + b)\n",
    "                    print(\"model saved to {}\".format(checkpoint_path))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
