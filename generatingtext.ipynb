{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "\n",
    "import codecs\n",
    "import collections\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, data_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size, infer=False):#\n",
    "\n",
    "        \n",
    "        if infer:\n",
    "            batch_size = 1\n",
    "            seq_length = 1\n",
    "\n",
    "        \n",
    "        cell_fn = rnn.BasicLSTMCell\n",
    "\n",
    "        cells = []\n",
    "        for _ in range(num_layers):\n",
    "            cell = cell_fn(rnn_size)\n",
    "            cells.append(cell)\n",
    "        self.cell = cell = rnn.MultiRNNCell(cells)\n",
    "        self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.targets = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "        self.initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        self.batch_pointer = tf.Variable(0, name=\"batch_pointer\", trainable=True, dtype=tf.int32)\n",
    "        self.inc_batch_pointer_op = tf.assign(self.batch_pointer, self.batch_pointer + 1)\n",
    "        self.epoch_pointer = tf.Variable(0, name=\"epoch_pointer\", trainable=False)\n",
    "        self.batch_time = tf.Variable(0.0, name=\"batch_time\", trainable=False)\n",
    "        tf.summary.scalar(\"time_batch\", self.batch_time)\n",
    "        def variable_summaries(var):\n",
    "            with tf.name_scope('summaries'):\n",
    "                mean = tf.reduce_mean(var)\n",
    "                tf.summary.scalar('mean', mean)\n",
    "                tf.summary.scalar('max', tf.reduce_max(var))\n",
    "                tf.summary.scalar('min', tf.reduce_min(var))\n",
    "\n",
    "        with tf.variable_scope('rnnlm'):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "            variable_summaries(softmax_w)\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "            variable_summaries(softmax_b)\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "                inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), seq_length, 1)\n",
    "                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, loop_function=loop, scope='rnnlm')\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                [tf.reshape(self.targets, [-1])],\n",
    "                [tf.ones([batch_size * seq_length])],\n",
    "                vocab_size)\n",
    "        self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        tf.summary.scalar(\"cost\", self.cost)\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),\n",
    "                grad_clip)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    def sample(self, sess, words, vocab, num, prime='first', sampling_type=1):\n",
    "        '''\n",
    "        This function is used to generate text, based on a saved model, with\n",
    "        a text as input.\n",
    "        It returns a string, composed of words chosen one by one by the model.\n",
    "        '''\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "\n",
    "        \n",
    "        ret = ''\n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "        ret = prime\n",
    "        word = prime.split()[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab.get(word, 0)\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = probs[0]\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if word == '\\n':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else:\n",
    "                sample = weighted_pick(p)\n",
    "            pred = words[sample]\n",
    "            ret += ' ' + pred\n",
    "            word = pred\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-eaa56d45b15d>:30: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "None\n",
      "INFO:tensorflow:Restoring parameters from /home/vibertron/Desktop/model_test.ckpt-99\n"
     ]
    }
   ],
   "source": [
    "#data_dir = \"C:\\\\Users\\\\SAIKUMAR\\\\Desktop\\\\vikram vqa\"\n",
    "data_dir= \"/home/vibertron/Desktop\"\n",
    "rnn_size = 256 \n",
    "num_layers = 2 \n",
    "model = 'lstm' \n",
    "batch_size = 5 \n",
    "seq_length = 25 \n",
    "num_epochs = 50 \n",
    "save_every = 100 \n",
    "grad_clip = 5. \n",
    "learning_rate= 0.002 \n",
    "decay_rate = 0.97 \n",
    "gpu_mem = 0.666 \n",
    "init_from = None\n",
    "#input_file = os.path.join(data_dir, \"corp.txt\")\n",
    "vocab_file = os.path.join(data_dir, \"vocab1.pkl\")\n",
    "#with codecs.open(input_file, \"r\", encoding='utf8') as f:\n",
    "\n",
    "f=\"\"\"YOU don't know about me without you have read a book by the name of The\n",
    "Adventures of Tom Sawyer; but that ain't no matter.  That book was made\n",
    "by Mr. Mark Twain, and he told the truth, mainly.  There was things\n",
    "which he stretched, but mainly he told the truth.  That is nothing.  I\n",
    "never seen anybody but lied one time or another, without it was Aunt\n",
    "Polly, or the widow, or maybe Mary.  Aunt Polly--Tom's Aunt Polly, she\n",
    "is--and Mary, and the Widow Douglas is all told about in that book, which\n",
    "is mostly a true book, with some stretchers, as I said before.\"\"\"\n",
    "\n",
    "data = f\n",
    "data = data.replace(\",\",\" \")\n",
    "data = data.replace(\".\",\" \")\n",
    "data = data.replace(\"''\",\" \")\n",
    "x_text = data.split()\n",
    "word_counts = collections.Counter(x_text)\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "vocab_size = len(words)\n",
    "n=200 \n",
    "prime = 'Il ' \n",
    "sample = 1 \n",
    "\n",
    "#with open(\"C:\\\\Users\\\\SAIKUMAR\\\\Desktop\\\\vikram vqa\\\\__MACOSX\\\\caption_sneak\\\\data\\\\vocab1.pkl\", 'rb') as f1:\n",
    "        #words, vocab = cPickle.load(f1)\n",
    "        \n",
    "model = Model(data_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size,True)\n",
    "with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #\"THIS CKPT IS THE PROBLEM, I AM UNABLE TO OBTAIN THE STATE OF THE CHECKPOINT\"\n",
    "        model_checkpoint_path=\"/home/vibertron/Desktop/model_test.ckpt-99\"\n",
    "        ckpt = tf.train.get_checkpoint_state(model_checkpoint_path)\n",
    "        print(ckpt)\n",
    "        saver.restore(sess,model_checkpoint_path)\n",
    "        results = model.sample(sess, words, vocab, n, prime, sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il  don't Aunt mainly know me me you no you you about or but Polly Mr it me about lied That ain't read is--and but said maybe is--and Twain Twain said said YOU which is--and it Twain about of in a another name Twain as time anybody true but don't it it with There nothing name matter mainly she matter matter she Polly--Tom's all made all stretchers you Widow seen you seen the seen seen truth that a which Mr seen have Mr but before have That before me have before ain't in read in before in but YOU in That maybe is--and before is--and have That no truth Aunt all Widow true I truth matter name matter stretched stretched matter things things things mainly mainly Polly--Tom's Polly--Tom's made stretchers by Adventures it it seen seen Widow the truth seen which have which the have Polly have no maybe which mostly which me maybe maybe have have That in YOU he in That Twain That ain't Twain ain't the lied in me said YOU anybody of true matter Aunt true as name she mainly matter she Polly--Tom's all matter Polly--Tom's by Polly--Tom's by you stretchers seen Widow seen have that seen\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
